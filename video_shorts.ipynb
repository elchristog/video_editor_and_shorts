{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "057959d8",
   "metadata": {},
   "source": [
    "# Editor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683e6380",
   "metadata": {},
   "source": [
    "## **Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd3efc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elchristog/video_editor_and_shorts/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funciones e importaciones (V2.0 - Estable) listas.\n",
      "API Key cargada y configurada.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CELDA 1: IMPORTACIONES Y DEFINICI√ìN DE FUNCIONES (¬°VERSI√ìN 2.0 ACTUALIZADA!)\n",
    "# (Ejecutar esta celda una sola vez)\n",
    "# ==============================================================================\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import webvtt\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "import sys\n",
    "from moviepy.editor import VideoFileClip, concatenate_videoclips, TextClip, CompositeVideoClip, ImageClip\n",
    "from io import StringIO\n",
    "import requests\n",
    "import shutil\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- ¬°NUEVOS IMPORTS PARA LA SOLUCI√ìN ESTABLE DE EMOJIS! ---\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "print(\"Funciones e importaciones (V2.0 - Estable) listas.\")\n",
    "\n",
    "# --- Cargar API Key ---\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "if API_KEY:\n",
    "    genai.configure(api_key=API_KEY)\n",
    "    print(\"API Key cargada y configurada.\")\n",
    "else:\n",
    "    print(\"ADVERTENCIA: No se encontr√≥ API_KEY en el archivo .env\", file=sys.stderr)\n",
    "\n",
    "\n",
    "# --- FUNCIONES DE TIEMPO (Sin Cambios) ---\n",
    "def to_seconds(time_str):\n",
    "    try:\n",
    "        time_str = time_str.split('.')[0]\n",
    "        parts = list(map(int, time_str.split(':')))\n",
    "        if len(parts) == 3:  # HH:MM:SS\n",
    "            h, m, s = parts\n",
    "            return h * 3600 + m * 60 + s\n",
    "        elif len(parts) == 2:  # MM:SS\n",
    "            m, s = parts\n",
    "            return m * 60 + s\n",
    "        else:\n",
    "            raise ValueError(\"Formato de tiempo no v√°lido\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error al convertir tiempo '{time_str}': {e}\", file=sys.stderr)\n",
    "        return 0\n",
    "\n",
    "def from_seconds(total_seconds):\n",
    "    h = int(total_seconds // 3600)\n",
    "    m = int((total_seconds % 3600) // 60)\n",
    "    s = int(total_seconds % 60)\n",
    "    return f\"{h:02}:{m:02}:{s:02}\"\n",
    "\n",
    "# --- FUNCI√ìN UTILITARIA PARA DESCARGAR FUENTE DE EMOJIS (Sin Cambios) ---\n",
    "def descargar_fuente_emoji(font_path=\"NotoColorEmoji.ttf\"):\n",
    "    print(f\"Buscando la fuente de emoji local: {font_path}...\")\n",
    "    if os.path.exists(font_path):\n",
    "        print(f\"Fuente de emoji encontrada: {font_path}\")\n",
    "        return font_path\n",
    "    else:\n",
    "        print(\"--- ¬°ERROR GRAVE! ---\", file=sys.stderr)\n",
    "        print(f\"No se pudo encontrar el archivo de fuente: {font_path}\", file=sys.stderr)\n",
    "        print(\"Por favor, descarga la fuente manualmente desde:\", file=sys.stderr)\n",
    "        print(\"https://github.com/googlefonts/noto-emoji/raw/main/fonts/NotoColorEmoji.ttf\", file=sys.stderr)\n",
    "        print(\"Y gu√°rdala en la misma carpeta que este script.\", file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "# --- FUNCI√ìN DE SUBT√çTULOS (V4 - S√öPER ROBUSTA - ARREGLA PARSER!) ---\n",
    "def leer_subtitulos_locales(vtt_path):\n",
    "    captions = None\n",
    "    transcript = \"\"\n",
    "    try:\n",
    "        print(f\"Leyendo archivo de subt√≠tulos local: {vtt_path}...\")\n",
    "        if not os.path.exists(vtt_path):\n",
    "            raise FileNotFoundError(f\"No se pudo encontrar el archivo de subt√≠tulos en: {vtt_path}\")\n",
    "        \n",
    "        # 1. Leer con 'utf-8-sig' para manejar BOM (caracteres invisibles al inicio)\n",
    "        with open(vtt_path, 'r', encoding='utf-8-sig') as f:\n",
    "            vtt_content_raw = f.read()\n",
    "\n",
    "        # 2. Buscar \"WEBVTT\"\n",
    "        start_index = vtt_content_raw.find(\"WEBVTT\")\n",
    "        if start_index == -1:\n",
    "            raise ValueError(\"El archivo VTT no contiene el header 'WEBVTT' requerido.\")\n",
    "\n",
    "        # 3. Cortar todo lo que est√© ANTES de \"WEBVTT\"\n",
    "        vtt_content_cortado = vtt_content_raw[start_index:]\n",
    "        \n",
    "        # 4. Dividir en l√≠neas\n",
    "        lines = vtt_content_cortado.splitlines()\n",
    "        \n",
    "        # 5. Forzar la primera l√≠nea a ser solo \"WEBVTT\" (elimina \" - Subtitles by...\")\n",
    "        lines[0] = \"WEBVTT\"\n",
    "        \n",
    "        # --- ¬°NUEVA L√ìGICA V4! ---\n",
    "        # El parser VTT REQUIERE un salto de l√≠nea despu√©s del header.\n",
    "        # Las versiones anteriores lo borraban. Esta V4 lo preserva.\n",
    "        cleaned_lines = []\n",
    "        header_terminado = False\n",
    "        for line in lines:\n",
    "            if not header_terminado:\n",
    "                # Estamos en el bloque del header (WEBVTT, NOTE, etc.)\n",
    "                cleaned_lines.append(line)\n",
    "                if line.strip() == \"\":\n",
    "                    # Encontramos el primer salto de l√≠nea, el header termin√≥.\n",
    "                    header_terminado = True\n",
    "            else:\n",
    "                # Estamos en el cuerpo de los subt√≠tulos, a√±adir todo.\n",
    "                cleaned_lines.append(line)\n",
    "        \n",
    "        vtt_content_limpio = \"\\n\".join(cleaned_lines)\n",
    "        \n",
    "        # 8. Usar el contenido limpio para el parser\n",
    "        captions = webvtt.read_buffer(StringIO(vtt_content_limpio))\n",
    "        \n",
    "        if not captions:\n",
    "             raise Exception(\"El parser VTT no pudo leer ning√∫n subt√≠tulo despu√©s de limpiar.\")\n",
    "\n",
    "        # El resto de la funci√≥n sigue igual\n",
    "        for caption in captions:\n",
    "            timestamp = caption.start\n",
    "            timestamp_clean = timestamp.split('.')[0]\n",
    "            transcript += f\"[{timestamp_clean}] {caption.text.strip().replace(chr(10), ' ')}\\n\"\n",
    "        \n",
    "        print(f\"Subt√≠tulos le√≠dos y formateados exitosamente. (Parser V4)\")\n",
    "        return transcript, captions\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error leyendo o procesando el archivo VTT: {e}\", file=sys.stderr)\n",
    "        return None, None\n",
    "    \n",
    "    \n",
    "\n",
    "# --- FUNCI√ìN DE IA (CORTES) (SIMPLIFICADA - SOLO MULETILLAS) ---\n",
    "def obtener_cortes_para_eliminar(transcripcion, duracion_minima_seg=0.1):\n",
    "    print(f\"Conectando con Gemini para analizar relleno verbal (duraci√≥n > {duracion_minima_seg}s)...\")\n",
    "    try:\n",
    "        model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "        prompt = f\"\"\"\n",
    "        Eres un editor de video cuya tarea es eliminar \"relleno\" obvio\n",
    "        de una transcripci√≥n.\n",
    "\n",
    "        Analiza la siguiente transcripci√≥n e identifica segmentos para ELIMINAR\n",
    "        basado en dos criterios. S√© muy conservador.\n",
    "\n",
    "        CRITERIOS PARA ELIMINAR:\n",
    "        1.  **Muletillas / Rellenos:** Palabras o sonidos como 'ehh', 'mmm',\n",
    "            'pues...', 'esteee...', 'o sea...', 'bueno...'.\n",
    "            Tu objetivo es eliminar las que *interrumpen la fluidez*.\n",
    "        2.  **Reinicios Falsos CLAROS:** Oraciones que el orador\n",
    "            empieza, abandona a mitad de frase, y vuelve a empezar\n",
    "            (ej. \"Y el video... no, mejor dicho, el audio...\")\n",
    "\n",
    "        REGLAS CR√çTICAS:\n",
    "        -   **S√â CONSERVADOR.** Si dudas, NO LO CORTES.\n",
    "        -   Si el video est√° limpio, devuelve una lista vac√≠a [].\n",
    "\n",
    "        Tu respuesta DEBE ser √∫nicamente un objeto JSON:\n",
    "        - \"motivo\": (\"muletilla\", \"reinicio falso\")\n",
    "        - \"inicio\": El timestamp 'HH:MM:SS' de inicio.\n",
    "        - \"fin\": El timestamp 'HH:MM:SS' de fin.\n",
    "\n",
    "        Ejemplo de respuesta:\n",
    "        [\n",
    "          {{\"motivo\": \"muletilla\", \"inicio\": \"00:02:15\", \"fin\": \"00:02:17\"}}\n",
    "        ]\n",
    "\n",
    "        Aqu√≠ est√° la transcripci√≥n:\n",
    "        ---\n",
    "        {transcripcion}\n",
    "        ---\n",
    "        \"\"\"\n",
    "        response = model.generate_content(prompt)\n",
    "        cleaned_response = response.text.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "        print(\"An√°lisis de IA completado. Parseando y filtrando segmentos...\")\n",
    "        secciones = json.loads(cleaned_response)\n",
    "        \n",
    "        secciones_filtradas = []\n",
    "        for s in secciones:\n",
    "            try:\n",
    "                inicio_seg = to_seconds(s['inicio'])\n",
    "                fin_seg = to_seconds(s['fin'])\n",
    "                duracion_corte = fin_seg - inicio_seg\n",
    "                \n",
    "                if duracion_corte > 0 and duracion_corte >= duracion_minima_seg:\n",
    "                    secciones_filtradas.append(s)\n",
    "                else:\n",
    "                    print(f\"  ¬∑ Descartando corte de IA (duraci√≥n inv√°lida o muy corta): {s}\")\n",
    "            except Exception:\n",
    "                pass \n",
    "        \n",
    "        print(f\"Se identificaron {len(secciones_filtradas)} cortes de IA v√°lidos (duraci√≥n >= {duracion_minima_seg}s).\")\n",
    "        return secciones_filtradas\n",
    "    except Exception as e:\n",
    "        print(f\"Error al contactar con Gemini o parsear JSON: {e}\", file=sys.stderr)\n",
    "        return []\n",
    "\n",
    "\n",
    "\n",
    "# --- FUNCI√ìN DE IA PARA EMOJIS (Sin Cambios) ---\n",
    "def obtener_emojis_para_subtitulos(captions_obj, secciones_para_eliminar):\n",
    "    print(\"Conectando con Gemini para analizar y sugerir emojis...\")\n",
    "    if not captions_obj:\n",
    "        return []\n",
    "\n",
    "    cortes_seg = []\n",
    "    for corte in secciones_para_eliminar:\n",
    "        try:\n",
    "            cortes_seg.append((to_seconds(corte['inicio']), to_seconds(corte['fin'])))\n",
    "        except Exception:\n",
    "            continue\n",
    "            \n",
    "    captions_buenos = []\n",
    "    transcript_buena = \"\"\n",
    "    for cap in captions_obj:\n",
    "        es_bueno = True\n",
    "        for inicio, fin in cortes_seg:\n",
    "            if cap.start_in_seconds >= inicio and cap.start_in_seconds < fin:\n",
    "                es_bueno = False\n",
    "                break\n",
    "        if es_bueno:\n",
    "            captions_buenos.append(cap)\n",
    "            timestamp_clean = cap.start.split('.')[0]\n",
    "            transcript_buena += f\"[{timestamp_clean}] {cap.text.strip().replace(chr(10), ' ')}\\n\"\n",
    "\n",
    "    if not transcript_buena:\n",
    "        print(\"No se encontr√≥ transcripci√≥n v√°lida despu√©s del filtrado.\")\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "        prompt = f\"\"\"\n",
    "        Eres un editor de video creativo. Analiza la siguiente transcripci√≥n\n",
    "        e identifica palabras o frases clave que puedan ser realzadas\n",
    "        con un emoji relevante.\n",
    "\n",
    "        REGLAS:\n",
    "        1.  S√© selectivo. No a√±adas emojis a cada l√≠nea, solo a\n",
    "            conceptos visuales fuertes (ej. idea üí°, dinero üí∞,\n",
    "            r√°pido üöÄ, mundo üåç, amor ‚ù§Ô∏è, √©xito üèÜ).\n",
    "        2.  El emoji debe aparecer durante la palabra clave.\n",
    "        3.  El \"fin\" debe ser 1 o 2 segundos despu√©s del \"inicio\".\n",
    "        4.  Usa los timestamps originales del texto.\n",
    "\n",
    "        Tu respuesta DEBE ser √∫nicamente un objeto JSON (una lista de objetos):\n",
    "        - \"emoji\": El emoji unicode (ej. \"üí°\").\n",
    "        - \"inicio\": El timestamp 'HH:MM:SS' de inicio.\n",
    "        - \"fin\": El timestamp 'HH:MM:SS' de fin.\n",
    "\n",
    "        Ejemplo de respuesta:\n",
    "        [\n",
    "          {{\"emoji\": \"üí°\", \"inicio\": \"00:02:15\", \"fin\": \"00:02:17\"}},\n",
    "          {{\"emoji\": \"üí∞\", \"inicio\": \"00:05:31\", \"fin\": \"00:05:33\"}}\n",
    "        ]\n",
    "\n",
    "        Aqu√≠ est√° la transcripci√≥n:\n",
    "        ---\n",
    "        {transcript_buena}\n",
    "        ---\n",
    "        \"\"\"\n",
    "        response = model.generate_content(prompt)\n",
    "        cleaned_response = response.text.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "        print(\"An√°lisis de emojis completado.\")\n",
    "        return json.loads(cleaned_response)\n",
    "    except Exception as e:\n",
    "        print(f\"Error al contactar con Gemini para emojis: {e}\", file=sys.stderr)\n",
    "        return []\n",
    "\n",
    "\n",
    "# --- FUNCI√ìN DE SILENCIOS (¬°ACTUALIZADA V2 - MANEJA INICIO, FIN Y MEDIO!) ---\n",
    "def identificar_silencios_largos(captions_obj, video_duration, umbral_segundos=1.5):\n",
    "    \"\"\"\n",
    "    Identifica TODOS los silencios (inicio, medio, fin)\n",
    "    basado en los subt√≠tulos y un umbral.\n",
    "    \"\"\"\n",
    "    print(f\"Identificando silencios de inicio, fin y entre frases (umbral: {umbral_segundos}s)...\")\n",
    "    if not captions_obj or len(captions_obj) == 0:\n",
    "        return []\n",
    "        \n",
    "    silencios = []\n",
    "    \n",
    "    # 1. ORDENAR (Cr√≠tico para que la l√≥gica funcione)\n",
    "    try:\n",
    "        sorted_captions = sorted(captions_obj, key=lambda c: c.start_in_seconds)\n",
    "    except Exception as e:\n",
    "        print(f\"  ¬∑ ERROR: No se pudieron ordenar los subt√≠tulos (¬øparser VTT fall√≥?): {e}\", file=sys.stderr)\n",
    "        return []\n",
    "\n",
    "    # 2. SILENCIO INICIAL\n",
    "    # Queremos que el video empiece 1 seg ANTES de la primera palabra\n",
    "    inicio_habla_seg = sorted_captions[0].start_in_seconds\n",
    "    nuevo_inicio_video_seg = max(0, inicio_habla_seg - 1.0)\n",
    "    \n",
    "    if nuevo_inicio_video_seg > 0.1: # Solo cortar si el silencio es significativo\n",
    "        print(f\"  ¬∑ Silencio inicial detectado: 00:00:00 a {from_seconds(nuevo_inicio_video_seg)}\")\n",
    "        silencios.append({\n",
    "            \"motivo\": \"silencio_inicial\",\n",
    "            \"inicio\": from_seconds(0.0),\n",
    "            \"fin\": from_seconds(nuevo_inicio_video_seg)\n",
    "        })\n",
    "\n",
    "    # 3. SILENCIOS ENTRE FRASES (Tu petici√≥n)\n",
    "    for i in range(len(sorted_captions) - 1):\n",
    "        cap_actual = sorted_captions[i]\n",
    "        cap_siguiente = sorted_captions[i+1]\n",
    "        \n",
    "        # El 'gap' es el tiempo entre el fin de una frase y el inicio de la siguiente\n",
    "        gap = cap_siguiente.start_in_seconds - cap_actual.end_in_seconds\n",
    "        \n",
    "        if gap >= umbral_segundos:\n",
    "            # Cortar el 'gap', pero dejando 0.2s de 'aire'\n",
    "            # para que el corte no sea tan brusco\n",
    "            inicio_corte_gap = cap_actual.end_in_seconds + 0.1\n",
    "            fin_corte_gap = cap_siguiente.start_in_seconds - 0.1\n",
    "            \n",
    "            # Asegurarse de que el corte siga siendo v√°lido\n",
    "            if fin_corte_gap > inicio_corte_gap:\n",
    "                print(f\"  ¬∑ Silencio entre frases detectado: {from_seconds(inicio_corte_gap)} a {from_seconds(fin_corte_gap)}\")\n",
    "                silencios.append({\n",
    "                    \"motivo\": \"silencio largo\",\n",
    "                    \"inicio\": from_seconds(inicio_corte_gap),\n",
    "                    \"fin\": from_seconds(fin_corte_gap)\n",
    "                })\n",
    "\n",
    "    # 4. SILENCIO FINAL\n",
    "    # Queremos que el video termine 1 seg DESPU√âS de la √∫ltima palabra\n",
    "    fin_habla_seg = sorted_captions[-1].end_in_seconds\n",
    "    nuevo_fin_video_seg = min(video_duration, fin_habla_seg + 1.0)\n",
    "    \n",
    "    if (video_duration - nuevo_fin_video_seg) > 0.1: # Solo cortar si el silencio es significativo\n",
    "        print(f\"  ¬∑ Silencio final detectado: {from_seconds(nuevo_fin_video_seg)} a {from_seconds(video_duration)}\")\n",
    "        silencios.append({\n",
    "            \"motivo\": \"silencio_final\",\n",
    "            \"inicio\": from_seconds(nuevo_fin_video_seg),\n",
    "            \"fin\": from_seconds(video_duration)\n",
    "        })\n",
    "        \n",
    "    return silencios\n",
    "\n",
    "\n",
    "# --- FUNCI√ìN DE ENSAMBLAJE (V3 - CON ZOOM DIN√ÅMICO y ENTRADA SIMPLE) ---\n",
    "def ensamblar_video_editado(video_local_path, secciones_para_eliminar, video_final_path):\n",
    "    \"\"\"\n",
    "    Ensambla el video final.\n",
    "    - Recibe la lista COMPLETA de cortes (IA + Silencios).\n",
    "    - ¬°Aplica un zoom alternado (1.05x) a los clips para dinamismo!\n",
    "    \"\"\"\n",
    "    video_original_path = \"video_original_para_editar.mp4\"\n",
    "    try:\n",
    "        print(f\"Usando video local: {video_local_path}\")\n",
    "        if not os.path.exists(video_local_path):\n",
    "            raise FileNotFoundError(f\"No se pudo encontrar el archivo de video en: {video_local_path}\")\n",
    "        \n",
    "        print(f\"Copiando video a la ruta de trabajo temporal: {video_original_path}...\")\n",
    "        shutil.copy(video_local_path, video_original_path)\n",
    "        print(\"Copia completada.\")\n",
    "        \n",
    "        video = VideoFileClip(video_original_path)\n",
    "        video_duration = video.duration\n",
    "        \n",
    "        # --- L√ìGICA DE ZOOM DIN√ÅMICO ---\n",
    "        W, H = video.size\n",
    "        ZOOM_LEVEL = 1.05 # Zoom del 5%\n",
    "        print(f\"Zoom din√°mico habilitado (Nivel: {ZOOM_LEVEL}, Base: {W}x{H})\")\n",
    "        # ------------------------------\n",
    "        \n",
    "        if not secciones_para_eliminar:\n",
    "            print(\"No se especificaron cortes. El video no ser√° modificado.\")\n",
    "            video.close()\n",
    "            # (Correcci√≥n) Si no hay cortes, APLICAR EL ZOOM a todo el clip\n",
    "            # para que el video_cortado tenga el tama√±o correcto (par)\n",
    "            video_zoom = video.resize(ZOOM_LEVEL).crop(x_center=W/2, y_center=H/2, width=W, height=H)\n",
    "            video_final = concatenate_videoclips([video.subclip(0, 0.01), video_zoom.subclip(0.01)])\n",
    "            video_final.write_videofile(video_final_path, codec=\"libx264\", audio_codec=\"aac\", logger=None)\n",
    "            video_final.close()\n",
    "            video_zoom.close()\n",
    "            print(\"Video sin cortes, pero re-codificado para asegurar consistencia.\")\n",
    "            return video_final_path\n",
    "\n",
    "        # 1. Fusionar cortes (l√≥gica movida aqu√≠, desde tu celda 3)\n",
    "        cortes_ordenados = sorted(secciones_para_eliminar, key=lambda x: to_seconds(x['inicio']))\n",
    "        cortes_fusionados = []\n",
    "        if cortes_ordenados:\n",
    "            current_merged_corte = cortes_ordenados[0]\n",
    "            for i in range(1, len(cortes_ordenados)):\n",
    "                next_corte = cortes_ordenados[i]\n",
    "                current_fin_seg = to_seconds(current_merged_corte['fin'])\n",
    "                next_inicio_seg = to_seconds(next_corte['inicio'])\n",
    "                \n",
    "                if next_inicio_seg <= current_fin_seg + 0.1: \n",
    "                    current_merged_corte['fin'] = from_seconds(max(current_fin_seg, to_seconds(next_corte['fin'])))\n",
    "                else:\n",
    "                    cortes_fusionados.append(current_merged_corte)\n",
    "                    current_merged_corte = next_corte\n",
    "            cortes_fusionados.append(current_merged_corte)\n",
    "        \n",
    "        print(\"\\n--- Segmentos a ELIMINAR (final, despu√©s de fusi√≥n) ---\")\n",
    "        print(json.dumps(cortes_fusionados, indent=2, ensure_ascii=False))\n",
    "        print(\"--------------------------------------------------\\n\")\n",
    "\n",
    "        # 2. Crear clips buenos (¬°CON L√ìGICA DE ZOOM!)\n",
    "        clips_buenos = []\n",
    "        current_time_seg = 0.0\n",
    "        \n",
    "        for corte in cortes_fusionados:\n",
    "            inicio_corte_seg = to_seconds(corte['inicio'])\n",
    "            fin_corte_seg = to_seconds(corte['fin'])\n",
    "            \n",
    "            if inicio_corte_seg > video_duration: break \n",
    "            \n",
    "            if fin_corte_seg > (video_duration + 100):\n",
    "                fin_corte_seg = video_duration\n",
    "            elif fin_corte_seg > video_duration:\n",
    "                 fin_corte_seg = video_duration\n",
    "\n",
    "            inicio_corte_seg = max(current_time_seg, inicio_corte_seg)\n",
    "\n",
    "            if (inicio_corte_seg - current_time_seg) > 0.05: \n",
    "                print(f\"Manteniendo clip: {from_seconds(current_time_seg)} a {from_seconds(inicio_corte_seg)}\")\n",
    "                sub = video.subclip(current_time_seg, inicio_corte_seg)\n",
    "                \n",
    "                if len(clips_buenos) % 2 == 1:\n",
    "                    print(f\"  ¬∑ Aplicando zoom a clip #{len(clips_buenos)}\")\n",
    "                    sub = sub.resize(ZOOM_LEVEL).crop(x_center=W/2, y_center=H/2, width=W, height=H)\n",
    "                \n",
    "                clips_buenos.append(sub)\n",
    "            \n",
    "            current_time_seg = max(current_time_seg, fin_corte_seg)\n",
    "\n",
    "        # 3. A√±adir el √∫ltimo segmento (¬°CON L√ìGICA DE ZOOM!)\n",
    "        if (video_duration - current_time_seg) > 0.05:\n",
    "            print(f\"Manteniendo clip final: {from_seconds(current_time_seg)} a {from_seconds(video_duration)}\")\n",
    "            sub = video.subclip(current_time_seg, video_duration)\n",
    "            \n",
    "            if len(clips_buenos) % 2 == 1:\n",
    "                 print(f\"  ¬∑ Aplicando zoom a clip final #{len(clips_buenos)}\")\n",
    "                 sub = sub.resize(ZOOM_LEVEL).crop(x_center=W/2, y_center=H/2, width=W, height=H)\n",
    "                 \n",
    "            clips_buenos.append(sub)\n",
    "\n",
    "        if not clips_buenos:\n",
    "            print(\"Advertencia: La l√≥gica de cortes result√≥ en un video vac√≠o.\")\n",
    "            video.close()\n",
    "            return None\n",
    "        \n",
    "        print(f\"\\nEnsamblando video final a partir de {len(clips_buenos)} clips (con zoom alternado)...\")\n",
    "        final_video = concatenate_videoclips(clips_buenos)\n",
    "        \n",
    "        final_video.write_videofile(video_final_path, codec=\"libx264\", audio_codec=\"aac\", logger=None)  \n",
    "        final_video.close()\n",
    "        \n",
    "        for clip in clips_buenos: clip.close() \n",
    "        video.close()\n",
    "        \n",
    "        # ¬°IMPORTANTE! Devolvemos los CORTES FUSIONADOS\n",
    "        # para que la funci√≥n de emoji use la lista correcta.\n",
    "        return video_final_path, cortes_fusionados\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Ha ocurrido un error al ensamblar el video: {e}\", file=sys.stderr)\n",
    "        return None, None\n",
    "    finally:\n",
    "        if os.path.exists(video_original_path):\n",
    "            os.remove(video_original_path)\n",
    "\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# --- ¬°¬°¬°FUNCI√ìN DE COMPOSICI√ìN DE EMOJIS (V2.1 - CORRIGE 'pixel size')!!! ---\n",
    "# ==============================================================================\n",
    "def crear_video_con_emojis(video_base_path, video_final_path, lista_emojis, secciones_para_eliminar):\n",
    "    \"\"\"\n",
    "    Toma el video base cortado y le superpone los emojis.\n",
    "    ¬°V2.1 - CORRIGE EL ERROR 'invalid pixel size' FORZANDO DIMENSIONES PARES!\n",
    "    \"\"\"\n",
    "    print(f\"Iniciando Etapa 2 (V2.1 - Estable): Superposici√≥n de Emojis en {video_base_path}...\")\n",
    "    \n",
    "    # --- Cach√© para no renderizar el mismo emoji mil veces ---\n",
    "    emoji_clip_cache = {}\n",
    "    \n",
    "    try:\n",
    "        # 1. Cargar la fuente de emoji (para Pillow)\n",
    "        font_path = descargar_fuente_emoji()\n",
    "        if not font_path:\n",
    "            raise Exception(\"La fuente de emojis no se pudo encontrar.\")\n",
    "        \n",
    "        # Ajusta el tama√±o de la fuente de Pillow\n",
    "        font_size = 100 \n",
    "        pil_font = ImageFont.truetype(font_path, font_size)\n",
    "        \n",
    "        # 2. Cargar video base\n",
    "        video_base = VideoFileClip(video_base_path)\n",
    "\n",
    "        # --- ¬°NUEVA CORRECCI√ìN para \"invalid pixel size\"! ---\n",
    "        # El c√≥dec libx264 (usado para MP4) falla si las \n",
    "        # dimensiones del video son n√∫meros impares.\n",
    "        w, h = video_base.size\n",
    "        new_w = w if w % 2 == 0 else w - 1 # Restar 1 si es impar\n",
    "        new_h = h if h % 2 == 0 else h - 1 # Restar 1 si es impar\n",
    "\n",
    "        if new_w != w or new_h != h:\n",
    "            print(f\"  ¬∑ ADVERTENCIA: Dimensiones impares detectadas ({w}x{h}).\")\n",
    "            print(f\"  ¬∑ Corrigiendo a ({new_w}x{new_h}) para evitar error de c√≥dec.\")\n",
    "            # Usamos crop() para recortar 1 p√≠xel, lo cual es m√°s r√°pido que resize()\n",
    "            video_base = video_base.crop(width=new_w, height=new_h, x_center=w/2, y_center=h/2)\n",
    "        # --- FIN DE LA CORRECCI√ìN ---\n",
    "        \n",
    "        # 3. Mapeador de timestamps (sin cambios)\n",
    "        cortes_procesados = sorted(\n",
    "            [{'inicio': to_seconds(c['inicio']), 'fin': to_seconds(c['fin'])} for c in secciones_para_eliminar],\n",
    "            key=lambda x: x['inicio']\n",
    "        )\n",
    "        def calcular_nuevo_timestamp(tiempo_original_seg):\n",
    "            tiempo_a_restar = 0.0\n",
    "            for corte in cortes_procesados:\n",
    "                if tiempo_original_seg > corte['fin']:\n",
    "                    tiempo_a_restar += (corte['fin'] - corte['inicio'])\n",
    "                elif tiempo_original_seg > corte['inicio']:\n",
    "                    tiempo_a_restar += (tiempo_original_seg - corte['inicio'])\n",
    "                    break\n",
    "            return max(0, tiempo_original_seg - tiempo_a_restar)\n",
    "\n",
    "        # 4. Crear los clips de IMAGEN para cada emoji\n",
    "        clips_de_emojis_finales = []\n",
    "        \n",
    "        for item in lista_emojis:\n",
    "            try:\n",
    "                emoji_char = item['emoji']\n",
    "                inicio_original = to_seconds(item['inicio'])\n",
    "                fin_original = to_seconds(item['fin'])\n",
    "                duracion = fin_original - inicio_original\n",
    "                if duracion <= 0.1: continue\n",
    "\n",
    "                nuevo_inicio = calcular_nuevo_timestamp(inicio_original)\n",
    "                if nuevo_inicio + duracion > video_base.duration:\n",
    "                    duracion = video_base.duration - nuevo_inicio\n",
    "                if duracion <= 0.1: continue\n",
    "\n",
    "                print(f\"  ¬∑ A√±adiendo emoji {emoji_char} en {from_seconds(nuevo_inicio)} (Original: {item['inicio']})\")\n",
    "\n",
    "                # --- ¬°AQU√ç EST√Å LA NUEVA L√ìGICA! ---\n",
    "                base_emoji_clip = None\n",
    "                if emoji_char in emoji_clip_cache:\n",
    "                    # Usar el clip base de la cach√©\n",
    "                    base_emoji_clip = emoji_clip_cache[emoji_char]\n",
    "                else:\n",
    "                    # 1. Crear una imagen transparente con Pillow\n",
    "                    canvas_size = int(font_size * 1.5)\n",
    "                    pil_image = Image.new(\"RGBA\", (canvas_size, canvas_size), (0, 0, 0, 0)) # Transparente\n",
    "                    draw = ImageDraw.Draw(pil_image)\n",
    "                    \n",
    "                    # 2. Dibujar el emoji en la imagen\n",
    "                    try:\n",
    "                        # Pillow >= 9.2.0 (preferido)\n",
    "                        draw.text((canvas_size//2, canvas_size//2), emoji_char, font=pil_font, anchor=\"mm\", embedded_color=True)\n",
    "                    except TypeError:\n",
    "                        # Pillow < 9.2.0 (fallback)\n",
    "                        draw.text((canvas_size//2, canvas_size//2), emoji_char, font=pil_font, embedded_color=True)\n",
    "\n",
    "                    # 3. Convertir la imagen de Pillow a un clip de MoviePy\n",
    "                    emoji_array = np.array(pil_image)\n",
    "                    base_emoji_clip = ImageClip(emoji_array)\n",
    "                    \n",
    "                    # 4. Guardar en cach√©\n",
    "                    emoji_clip_cache[emoji_char] = base_emoji_clip\n",
    "                \n",
    "                # 5. Aplicar duraci√≥n, posici√≥n y efectos al clip\n",
    "                final_clip = base_emoji_clip.copy().set_position(('center', 0.7), relative=True) \\\n",
    "                                             .set_start(nuevo_inicio) \\\n",
    "                                             .set_duration(duracion) \\\n",
    "                                             .fadein(0.2).fadeout(0.2)\n",
    "\n",
    "                clips_de_emojis_finales.append(final_clip)\n",
    "                # --- FIN DE LA NUEVA L√ìGICA ---\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error procesando emoji '{item}': {e}\", file=sys.stderr) \n",
    "\n",
    "        if not clips_de_emojis_finales:\n",
    "            print(\"No se generaron emojis (o todos fallaron). El video final es el video cortado.\")\n",
    "            video_base.close()\n",
    "            if os.path.exists(video_base_path) and not os.path.exists(video_final_path):\n",
    "                os.rename(video_base_path, video_final_path)\n",
    "            return video_final_path\n",
    "\n",
    "        # 5. Componer el video final\n",
    "        print(f\"Componiendo video base con {len(clips_de_emojis_finales)} emojis...\")\n",
    "        video_final_con_emojis = CompositeVideoClip([video_base] + clips_de_emojis_finales)\n",
    "        \n",
    "        video_final_con_emojis.write_videofile(\n",
    "            video_final_path,\n",
    "            codec=\"libx264\",\n",
    "            audio_codec=\"aac\",\n",
    "            logger=None\n",
    "        )\n",
    "        print(f\"\\n¬°Proceso completado! El video con emojis est√° en '{video_final_path}'.\")\n",
    "\n",
    "        # Limpieza\n",
    "        video_final_con_emojis.close()\n",
    "        video_base.close()\n",
    "        for clip in clips_de_emojis_finales: clip.close()\n",
    "\n",
    "        if os.path.exists(video_base_path):\n",
    "             os.remove(video_base_path)\n",
    "        return video_final_path\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Ha ocurrido un error al crear el video con emojis: {e}\", file=sys.stderr)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529e76c6",
   "metadata": {},
   "source": [
    "## **Configuraci√≥n (Variables y Rutas)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b71123e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key lista para usarse.\n",
      "Archivos de entrada encontrados. ¬°Todo listo!\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CELDA 2: CONFIGURACI√ìN DE RUTAS\n",
    "# (Define tus archivos de entrada y salida aqu√≠)\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "# --- Directorios ---\n",
    "OUTPUT_FOLDER = \"edited\"\n",
    "INPUT_FOLDER = \"to_edit\"\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "# --- Archivos de ENTRADA ---\n",
    "# (Aseg√∫rate de que existan)\n",
    "RUTA_VIDEO_LOCAL = os.path.join(INPUT_FOLDER, \"video.mp4\")\n",
    "RUTA_SUBTITULOS_LOCAL = os.path.join(INPUT_FOLDER, \"subs.vtt\")\n",
    "\n",
    "# --- Archivos de SALIDA (generados por los scripts) ---\n",
    "# Archivo intermedio del Paso 1\n",
    "RUTA_VIDEO_CORTADO = os.path.join(OUTPUT_FOLDER, \"video_cortado.mp4\")\n",
    "# Archivo de metadatos para comunicar los pasos\n",
    "METADATA_FILE = os.path.join(OUTPUT_FOLDER, \"metadata_cortes.json\")\n",
    "# Archivo final del Paso 2\n",
    "RUTA_VIDEO_FINAL_EMOJIS = os.path.join(OUTPUT_FOLDER, \"video_final_con_emojis.mp4\")\n",
    "\n",
    "# --- Chequeo de API Key ---\n",
    "if not API_KEY or \"TU_API_KEY_AQUI\" in API_KEY:\n",
    "    print(\"Error: No se encontr√≥ la API_KEY.\", file=sys.stderr)\n",
    "    print(\"Aseg√∫rate de tener un archivo .env con 'API_KEY=tu_clave'\", file=sys.stderr)\n",
    "else:\n",
    "    print(f\"API Key lista para usarse.\")\n",
    "\n",
    "# --- Chequeo de Archivos de Entrada ---\n",
    "if not os.path.exists(RUTA_VIDEO_LOCAL):\n",
    "    print(f\"Error: El archivo de video no se encuentra en '{RUTA_VIDEO_LOCAL}'\", file=sys.stderr)\n",
    "elif not os.path.exists(RUTA_SUBTITULOS_LOCAL):\n",
    "    print(f\"Error: El archivo de subt√≠tulos no se encuentra en '{RUTA_SUBTITULOS_LOCAL}'\", file=sys.stderr)\n",
    "else:\n",
    "    print(\"Archivos de entrada encontrados. ¬°Todo listo!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd35c3dd",
   "metadata": {},
   "source": [
    "## **Cortar el Video**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e190adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INICIANDO ETAPA 1: CORTE DE VIDEO ---\n",
      "Leyendo archivo de subt√≠tulos local: to_edit/subs.vtt...\n",
      "Subt√≠tulos le√≠dos y formateados exitosamente. (Parser V4)\n",
      "Obteniendo duraci√≥n de to_edit/video.mp4...\n",
      "Duraci√≥n total del video: 00:12:18\n",
      "Conectando con Gemini para analizar relleno verbal (duraci√≥n > 0.1s)...\n",
      "An√°lisis de IA completado. Parseando y filtrando segmentos...\n",
      "Se identificaron 33 cortes de IA v√°lidos (duraci√≥n >= 0.1s).\n",
      "Identificando silencios de inicio, fin y entre frases (umbral: 1.5s)...\n",
      "  ¬∑ Silencio inicial detectado: 00:00:00 a 00:00:01\n",
      "\n",
      "--- Segmentos totales a eliminar (antes de fusi√≥n) ---\n",
      "[\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:00:13\",\n",
      "    \"fin\": \"00:00:15\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:00:36\",\n",
      "    \"fin\": \"00:00:37\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:01:19\",\n",
      "    \"fin\": \"00:01:20\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:01:20\",\n",
      "    \"fin\": \"00:01:22\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:01:31\",\n",
      "    \"fin\": \"00:01:32\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:02:04\",\n",
      "    \"fin\": \"00:02:05\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:02:22\",\n",
      "    \"fin\": \"00:02:23\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:02:33\",\n",
      "    \"fin\": \"00:02:34\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:03:13\",\n",
      "    \"fin\": \"00:03:14\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:03:23\",\n",
      "    \"fin\": \"00:03:24\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:04:04\",\n",
      "    \"fin\": \"00:04:05\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:04:05\",\n",
      "    \"fin\": \"00:04:07\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:04:25\",\n",
      "    \"fin\": \"00:04:26\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:04:30\",\n",
      "    \"fin\": \"00:04:31\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:05:04\",\n",
      "    \"fin\": \"00:05:05\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:05:06\",\n",
      "    \"fin\": \"00:05:07\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:06:26\",\n",
      "    \"fin\": \"00:06:27\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:07:17\",\n",
      "    \"fin\": \"00:07:18\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:07:19\",\n",
      "    \"fin\": \"00:07:20\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:07:20\",\n",
      "    \"fin\": \"00:07:21\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:07:54\",\n",
      "    \"fin\": \"00:07:55\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:08:03\",\n",
      "    \"fin\": \"00:08:04\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:08:59\",\n",
      "    \"fin\": \"00:09:00\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:09:04\",\n",
      "    \"fin\": \"00:09:05\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:10:25\",\n",
      "    \"fin\": \"00:10:26\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:10:33\",\n",
      "    \"fin\": \"00:10:34\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:10:36\",\n",
      "    \"fin\": \"00:10:37\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:10:37\",\n",
      "    \"fin\": \"00:10:38\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:10:50\",\n",
      "    \"fin\": \"00:10:51\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:11:02\",\n",
      "    \"fin\": \"00:11:03\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:11:07\",\n",
      "    \"fin\": \"00:11:08\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:12:01\",\n",
      "    \"fin\": \"00:12:02\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:12:17\",\n",
      "    \"fin\": \"00:12:18\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"silencio_inicial\",\n",
      "    \"inicio\": \"00:00:00\",\n",
      "    \"fin\": \"00:00:01\"\n",
      "  }\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "Usando video local: to_edit/video.mp4\n",
      "Copiando video a la ruta de trabajo temporal: video_original_para_editar.mp4...\n",
      "Copia completada.\n",
      "Zoom din√°mico habilitado (Nivel: 1.05, Base: 1280x720)\n",
      "\n",
      "--- Segmentos a ELIMINAR (final, despu√©s de fusi√≥n) ---\n",
      "[\n",
      "  {\n",
      "    \"motivo\": \"silencio_inicial\",\n",
      "    \"inicio\": \"00:00:00\",\n",
      "    \"fin\": \"00:00:01\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:00:13\",\n",
      "    \"fin\": \"00:00:15\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:00:36\",\n",
      "    \"fin\": \"00:00:37\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:01:19\",\n",
      "    \"fin\": \"00:01:22\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:01:31\",\n",
      "    \"fin\": \"00:01:32\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:02:04\",\n",
      "    \"fin\": \"00:02:05\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:02:22\",\n",
      "    \"fin\": \"00:02:23\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:02:33\",\n",
      "    \"fin\": \"00:02:34\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:03:13\",\n",
      "    \"fin\": \"00:03:14\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:03:23\",\n",
      "    \"fin\": \"00:03:24\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:04:04\",\n",
      "    \"fin\": \"00:04:07\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:04:25\",\n",
      "    \"fin\": \"00:04:26\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:04:30\",\n",
      "    \"fin\": \"00:04:31\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:05:04\",\n",
      "    \"fin\": \"00:05:05\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:05:06\",\n",
      "    \"fin\": \"00:05:07\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:06:26\",\n",
      "    \"fin\": \"00:06:27\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:07:17\",\n",
      "    \"fin\": \"00:07:18\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:07:19\",\n",
      "    \"fin\": \"00:07:21\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:07:54\",\n",
      "    \"fin\": \"00:07:55\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:08:03\",\n",
      "    \"fin\": \"00:08:04\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:08:59\",\n",
      "    \"fin\": \"00:09:00\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:09:04\",\n",
      "    \"fin\": \"00:09:05\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:10:25\",\n",
      "    \"fin\": \"00:10:26\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:10:33\",\n",
      "    \"fin\": \"00:10:34\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:10:36\",\n",
      "    \"fin\": \"00:10:38\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:10:50\",\n",
      "    \"fin\": \"00:10:51\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:11:02\",\n",
      "    \"fin\": \"00:11:03\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:11:07\",\n",
      "    \"fin\": \"00:11:08\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:12:01\",\n",
      "    \"fin\": \"00:12:02\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:12:17\",\n",
      "    \"fin\": \"00:12:18\"\n",
      "  }\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "Manteniendo clip: 00:00:01 a 00:00:13\n",
      "Manteniendo clip: 00:00:15 a 00:00:36\n",
      "  ¬∑ Aplicando zoom a clip #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ha ocurrido un error al ensamblar el video: module 'PIL.Image' has no attribute 'ANTIALIAS'\n",
      "El proceso (Etapa 1) fall√≥: Fall√≥ la etapa de corte de video.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CELDA 3: PASO 1 - AN√ÅLISIS Y CORTE DE VIDEO (¬°VERSI√ìN ACTUALIZADA!)\n",
    "# (Produce 'video_cortado.mp4' y 'metadata_cortes.json')\n",
    "# ==============================================================================\n",
    "print(\"--- INICIANDO ETAPA 1: CORTE DE VIDEO ---\")\n",
    "\n",
    "try:\n",
    "    # ETAPA 0: OBTENER DATOS\n",
    "    transcripcion, subtitulos_obj = leer_subtitulos_locales(RUTA_SUBTITULOS_LOCAL)\n",
    "    if not transcripcion or not subtitulos_obj:\n",
    "        raise Exception(\"No se pudo obtener la transcripci√≥n o los subt√≠tulos del archivo local.\")\n",
    "\n",
    "    # --- ¬°NUEVO PASO! Obtener duraci√≥n del video para el an√°lisis de silencio ---\n",
    "    print(f\"Obteniendo duraci√≥n de {RUTA_VIDEO_LOCAL}...\")\n",
    "    with VideoFileClip(RUTA_VIDEO_LOCAL) as temp_video:\n",
    "        duracion_total = temp_video.duration\n",
    "    print(f\"Duraci√≥n total del video: {from_seconds(duracion_total)}\")\n",
    "    # ----------------------------------------------------------------------\n",
    "\n",
    "    # ETAPA 1: L√ìGICA DE CORTE (Con la nueva funci√≥n de silencios)\n",
    "    \n",
    "    # 1. Obtener cortes de muletillas/reinicios\n",
    "    cortes_ia = obtener_cortes_para_eliminar(transcripcion, duracion_minima_seg=0.1)\n",
    "    \n",
    "    # 2. Obtener TODOS los silencios (inicio, medio, fin)\n",
    "    cortes_silencio = identificar_silencios_largos(\n",
    "        captions_obj=subtitulos_obj,\n",
    "        video_duration=duracion_total, # <--- Argumento nuevo\n",
    "        umbral_segundos=1.5 # Puedes ajustar este umbral\n",
    "    )\n",
    "    \n",
    "    # 3. Combinar ambas listas\n",
    "    todos_los_cortes = cortes_ia + cortes_silencio\n",
    "\n",
    "    if not todos_los_cortes:\n",
    "        print(\"\\nIA y an√°lisis de silencios no encontraron nada que eliminar.\")\n",
    "        # (A√∫n as√≠, llamamos a ensamblar para que aplique el zoom y re-codifique)\n",
    "    else:\n",
    "        print(\"\\n--- Segmentos totales a eliminar (antes de fusi√≥n) ---\")\n",
    "        print(json.dumps(todos_los_cortes, indent=2, ensure_ascii=False))\n",
    "        print(\"--------------------------------------------------\\n\")\n",
    "\n",
    "    # ETAPA 1.5: ENSAMBLAR VIDEO BASE (Llamada simple)\n",
    "    # Esta funci√≥n ahora aplica el zoom y fusiona los cortes internamente\n",
    "    ruta_video_cortado_generado, cortes_reales_fusionados = ensamblar_video_editado(\n",
    "        RUTA_VIDEO_LOCAL, \n",
    "        todos_los_cortes,\n",
    "        RUTA_VIDEO_CORTADO\n",
    "    ) \n",
    "\n",
    "    if not ruta_video_cortado_generado:\n",
    "        raise Exception(\"Fall√≥ la etapa de corte de video.\")\n",
    "\n",
    "    print(f\"\\nEtapa 1 completada. Video cortado guardado en: {ruta_video_cortado_generado}\")\n",
    "\n",
    "    # --- GUARDAR METADATOS PARA EL PASO 2 ---\n",
    "    # ¬°IMPORTANTE! Guardamos los 'cortes_reales_fusionados' que \n",
    "    # devuelve la funci√≥n, no la lista original.\n",
    "    print(f\"Guardando metadatos de cortes en {METADATA_FILE}...\")\n",
    "    metadata = {\n",
    "        \"ruta_video_cortado\": ruta_video_cortado_generado,\n",
    "        \"todos_los_cortes\": cortes_reales_fusionados, # <--- ¬°CAMBIO CLAVE!\n",
    "        \"ruta_subtitulos_original\": RUTA_SUBTITULOS_LOCAL\n",
    "    }\n",
    "    with open(METADATA_FILE, 'w', encoding='utf-8') as f:\n",
    "        json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(\"\\n--- ¬°ETAPA 1 FINALIZADA! ---\")\n",
    "    print(f\"Video cortado: {ruta_video_cortado_generado}\")\n",
    "    print(f\"Metadatos: {METADATA_FILE}\")\n",
    "    print(\"\\nAhora puedes ejecutar la CELDA 4 para agregar emojis.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"El proceso (Etapa 1) fall√≥: {e}\", file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb5b495",
   "metadata": {},
   "source": [
    "## **Agregar Emojis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dcc0122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INICIANDO ETAPA 2: AGREGAR EMOJIS ---\n",
      "Cargando metadatos desde edited/metadata_cortes.json...\n",
      "Metadatos cargados exitosamente.\n",
      "Leyendo archivo de subt√≠tulos local: to_edit/subs.vtt...\n",
      "Subt√≠tulos le√≠dos y formateados exitosamente. (Parser V4)\n",
      "Conectando con Gemini para analizar y sugerir emojis...\n",
      "An√°lisis de emojis completado.\n",
      "\n",
      "--- Emojis sugeridos por la IA ---\n",
      "[\n",
      "  {\n",
      "    \"emoji\": \"üöÄ\",\n",
      "    \"inicio\": \"00:00:04\",\n",
      "    \"fin\": \"00:00:06\"\n",
      "  },\n",
      "  {\n",
      "    \"emoji\": \"‚úÖ\",\n",
      "    \"inicio\": \"00:00:27\",\n",
      "    \"fin\": \"00:00:29\"\n",
      "  },\n",
      "  {\n",
      "    \"emoji\": \"üí∞\",\n",
      "    \"inicio\": \"00:05:15\",\n",
      "    \"fin\": \"00:05:17\"\n",
      "  },\n",
      "  {\n",
      "    \"emoji\": \"üåç\",\n",
      "    \"inicio\": \"00:05:27\",\n",
      "    \"fin\": \"00:05:29\"\n",
      "  },\n",
      "  {\n",
      "    \"emoji\": \"‚úàÔ∏è\",\n",
      "    \"inicio\": \"00:07:38\",\n",
      "    \"fin\": \"00:07:40\"\n",
      "  },\n",
      "  {\n",
      "    \"emoji\": \"üéØ\",\n",
      "    \"inicio\": \"00:11:39\",\n",
      "    \"fin\": \"00:11:41\"\n",
      "  },\n",
      "  {\n",
      "    \"emoji\": \"üí∞\",\n",
      "    \"inicio\": \"00:11:44\",\n",
      "    \"fin\": \"00:11:46\"\n",
      "  },\n",
      "  {\n",
      "    \"emoji\": \"‚ù§Ô∏è\",\n",
      "    \"inicio\": \"00:12:13\",\n",
      "    \"fin\": \"00:12:15\"\n",
      "  }\n",
      "]\n",
      "------------------------------------\n",
      "\n",
      "Iniciando Etapa 2 (V2.1 - Estable): Superposici√≥n de Emojis en edited/video_cortado.mp4...\n",
      "Buscando la fuente de emoji local: NotoColorEmoji.ttf...\n",
      "Fuente de emoji encontrada: NotoColorEmoji.ttf\n",
      "Metadatos intermedios (edited/metadata_cortes.json) eliminados.\n",
      "\n",
      "--- ¬°ETAPA 2 FINALIZADA! ---\n",
      "Video final con emojis guardado en: edited/video_final_con_emojis.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ha ocurrido un error al crear el video con emojis: invalid pixel size\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# CELDA 4: PASO 2 - AGREGAR EMOJIS\n",
    "# (Lee 'video_cortado.mp4' y 'metadata_cortes.json', produce 'video_final_con_emojis.mp4')\n",
    "# ==============================================================================\n",
    "print(\"--- INICIANDO ETAPA 2: AGREGAR EMOJIS ---\")\n",
    "\n",
    "try:\n",
    "    # --- CARGAR METADATOS DEL PASO 1 ---\n",
    "    print(f\"Cargando metadatos desde {METADATA_FILE}...\")\n",
    "    if not os.path.exists(METADATA_FILE):\n",
    "        print(f\"Error: No se encuentra el archivo de metadatos '{METADATA_FILE}'.\", file=sys.stderr)\n",
    "        raise FileNotFoundError(\"Por favor, ejecuta la CELDA 3 primero.\")\n",
    "        \n",
    "    with open(METADATA_FILE, 'r', encoding='utf-8') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    # Extraer datos del JSON\n",
    "    ruta_video_cortado_leida = metadata.get(\"ruta_video_cortado\")\n",
    "    todos_los_cortes_leidos = metadata.get(\"todos_los_cortes\", [])\n",
    "    ruta_subtitulos_original_leida = metadata.get(\"ruta_subtitulos_original\")\n",
    "\n",
    "    # Validar que los archivos existan\n",
    "    if not ruta_video_cortado_leida or not os.path.exists(ruta_video_cortado_leida):\n",
    "        print(f\"Error: El video cortado '{ruta_video_cortado_leida}' no se encuentra.\", file=sys.stderr)\n",
    "        raise FileNotFoundError(\"Aseg√∫rate de que la CELDA 3 haya terminado correctamente.\")\n",
    "    \n",
    "    if not ruta_subtitulos_original_leida:\n",
    "        raise ValueError(\"El archivo de metadatos no especifica la ruta de los subt√≠tulos.\")\n",
    "\n",
    "    print(\"Metadatos cargados exitosamente.\")\n",
    "\n",
    "    # ETAPA 0 (Repetida): Necesitamos el objeto de subt√≠tulos de nuevo\n",
    "    _, subtitulos_obj_leidos = leer_subtitulos_locales(ruta_subtitulos_original_leida)\n",
    "    if not subtitulos_obj_leidos:\n",
    "        raise Exception(\"No se pudo volver a leer el archivo de subt√≠tulos.\")\n",
    "\n",
    "    # ETAPA 2: L√ìGICA DE EMOJIS\n",
    "    lista_emojis = obtener_emojis_para_subtitulos(subtitulos_obj_leidos, todos_los_cortes_leidos)\n",
    "\n",
    "    if not lista_emojis:\n",
    "        print(\"IA no sugiri√≥ emojis. El proceso ha finalizado.\")\n",
    "        if os.path.exists(ruta_video_cortado_leida) and not os.path.exists(RUTA_VIDEO_FINAL_EMOJIS):\n",
    "            os.rename(ruta_video_cortado_leida, RUTA_VIDEO_FINAL_EMOJIS)\n",
    "            print(f\"Video final (solo cortado) guardado como: {RUTA_VIDEO_FINAL_EMOJIS}\")\n",
    "    else:\n",
    "        print(\"\\n--- Emojis sugeridos por la IA ---\")\n",
    "        print(json.dumps(lista_emojis, indent=2, ensure_ascii=False))\n",
    "        print(\"------------------------------------\\n\")\n",
    "\n",
    "        # ETAPA 2.5: ENSAMBLAR VIDEO FINAL CON EMOJIS\n",
    "        crear_video_con_emojis(\n",
    "            ruta_video_cortado_leida,      # Input: El video ya cortado\n",
    "            RUTA_VIDEO_FINAL_EMOJIS,       # Output: El video final (de Celda 2)\n",
    "            lista_emojis,\n",
    "            todos_los_cortes_leidos\n",
    "        )\n",
    "        \n",
    "        # Limpieza final del archivo de metadatos, ya que el proceso se complet√≥\n",
    "        if os.path.exists(METADATA_FILE):\n",
    "            os.remove(METADATA_FILE)\n",
    "            print(f\"Metadatos intermedios ({METADATA_FILE}) eliminados.\")\n",
    "\n",
    "        print(\"\\n--- ¬°ETAPA 2 FINALIZADA! ---\")\n",
    "        print(f\"Video final con emojis guardado en: {RUTA_VIDEO_FINAL_EMOJIS}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"El proceso (Etapa 2) fall√≥: {e}\", file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b166c87d",
   "metadata": {},
   "source": [
    "# Shorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51efb2a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'moviepy.editor'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmoviepy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meditor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VideoFileClip\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StringIO\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mshutil\u001b[39;00m \u001b[38;5;66;03m# <-- ¬°NUEVO IMPORT!\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'moviepy.editor'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import webvtt\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "import sys\n",
    "from moviepy.editor import VideoFileClip\n",
    "from io import StringIO\n",
    "import shutil # <-- ¬°NUEVO IMPORT!\n",
    "\n",
    "def to_seconds(time_str):\n",
    "    \"\"\"Convierte un string de tiempo 'HH:MM:SS' o 'MM:SS' a segundos.\"\"\"\n",
    "    try:\n",
    "        # A√±adido para limpiar timestamps como '00:03:05.123'\n",
    "        time_str = time_str.split('.')[0]\n",
    "        parts = list(map(int, time_str.split(':')))\n",
    "        if len(parts) == 3:  # HH:MM:SS\n",
    "            h, m, s = parts\n",
    "            return h * 3600 + m * 60 + s\n",
    "        elif len(parts) == 2:  # MM:SS\n",
    "            m, s = parts\n",
    "            return m * 60 + s\n",
    "        else:\n",
    "            raise ValueError(\"Formato de tiempo no v√°lido\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error al convertir tiempo '{time_str}': {e}\", file=sys.stderr)\n",
    "        return 0\n",
    "\n",
    "# --- ¬°FUNCI√ìN MODIFICADA! ---\n",
    "def leer_subtitulos_locales(vtt_path):\n",
    "    \"\"\"\n",
    "    Lee un archivo .vtt local y lo devuelve\n",
    "    como un texto formateado Y como un objeto webvtt.\n",
    "    \"\"\"\n",
    "    captions = None\n",
    "    transcript = \"\"\n",
    "\n",
    "    try:\n",
    "        print(f\"Leyendo archivo de subt√≠tulos local: {vtt_path}...\")\n",
    "        if not os.path.exists(vtt_path):\n",
    "             raise FileNotFoundError(f\"No se pudo encontrar el archivo .vtt local: {vtt_path}\")\n",
    "\n",
    "        # La l√≥gica de parseo del script original es buena, la reutilizamos\n",
    "        captions = webvtt.read(vtt_path)\n",
    "        for caption in captions:\n",
    "            # Usamos la conversi√≥n de segundos para consistencia\n",
    "            secs = int(caption.start_in_seconds)\n",
    "            h = secs // 3600\n",
    "            m = (secs % 3600) // 60\n",
    "            s = secs % 60\n",
    "            timestamp = f\"{h:02}:{m:02}:{s:02}\"\n",
    "            transcript += f\"[{timestamp}] {caption.text.strip().replace(chr(10), ' ')}\\n\"\n",
    "\n",
    "        print(\"Subt√≠tulos le√≠dos y formateados exitosamente.\")\n",
    "        return transcript, captions\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extrayendo subt√≠tulos locales: {e}\", file=sys.stderr)\n",
    "        return None, None\n",
    "\n",
    "def obtener_clips_con_gemini(api_key, transcript):\n",
    "    \"\"\"\n",
    "    Env√≠a la transcripci√≥n a Gemini y le pide que identifique\n",
    "    secciones para shorts, devolviendo un JSON.\n",
    "    (Funci√≥n sin cambios)\n",
    "    \"\"\"\n",
    "    print(\"Conectando con Gemini para analizar momentos clave...\")\n",
    "    try:\n",
    "        genai.configure(api_key=api_key)\n",
    "\n",
    "        model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        Eres un experto productor de video y creador de contenido viral\n",
    "        para YouTube Shorts.\n",
    "\n",
    "        Tu tarea es analizar la siguiente transcripci√≥n de un video\n",
    "        (con marcas de tiempo [HH:MM:SS]) e identificar los 3 a 5\n",
    "        momentos m√°s impactantes, educativos o \"virales\" que ser√≠an\n",
    "        perfectos para YouTube Shorts.\n",
    "\n",
    "        Reglas para los clips:\n",
    "        1. Cada clip debe tener una duraci√≥n ideal de 30 a 55 segundos.\n",
    "        2. Los clips no deben superponerse.\n",
    "        3. Busca \"ganchos\" (preguntas, declaraciones impactantes),\n",
    "           res√∫menes de puntos clave o conclusiones claras.\n",
    "        4. **REGLA CR√çTICA DE COMPLETITUD:** El timestamp de 'fin' DEBE\n",
    "           corresponder al final de una oraci√≥n o una idea completa.\n",
    "           No cortes al orador a mitad de frase. Es PREFERIBLE que el\n",
    "           clip dure unos segundos m√É¬°s (hasta 59 segundos) para\n",
    "           asegurar que la idea se concluya, en lugar de cortarlo\n",
    "           abruptamente.\n",
    "\n",
    "        Tu respuesta DEBE ser √∫nicamente un objeto JSON, sin ning√∫n\n",
    "        otro texto, markdown o explicaci√É¬≥n.\n",
    "\n",
    "        El formato JSON debe ser una lista de objetos, donde cada\n",
    "        objeto tiene tres claves:\n",
    "        - \"nombre\": Un t√≠tulo corto y pegadizo para el clip (usa guiones bajos, sin espacios).\n",
    "        - \"inicio\": El timestamp 'HH:MM:SS' de inicio.\n",
    "        - \"fin\": El timestamp 'HH:MM:SS' de fin.\n",
    "\n",
    "        Ejemplo de respuesta:\n",
    "        [\n",
    "          {{\"nombre\": \"Error_Comun_al_Estudiar\", \"inicio\": \"00:03:05\", \"fin\": \"00:03:52\"}},\n",
    "          {{\"nombre\": \"Rese√±a_Libro_Saunders\", \"inicio\": \"00:08:05\", \"fin\": \"00:08:47\"}}\n",
    "        ]\n",
    "\n",
    "        Aqu√≠ est√° la transcripci√≥n:\n",
    "        ---\n",
    "        {transcript}\n",
    "        ---\n",
    "        \"\"\"\n",
    "\n",
    "        response = model.generate_content(prompt)\n",
    "\n",
    "        cleaned_response = response.text.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "\n",
    "        print(\"An√°lisis de IA completado. Parseando secciones...\")\n",
    "        secciones = json.loads(cleaned_response)\n",
    "        return secciones\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al contactar con Gemini o parsear JSON: {e}\", file=sys.stderr)\n",
    "        if \"404\" in str(e) and \"is not found\" in str(e):\n",
    "            print(\"\\n--- ¬°PROBLEMA DE API! ---\", file=sys.stderr)\n",
    "            print(\"Error 404: El modelo no se encuentra.\", file=sys.stderr)\n",
    "            print(\"Esto casi siempre significa que tu API KEY tiene un problema.\", file=sys.stderr)\n",
    "            print(\"1. Tu clave de API fue (o ser√°) desactivada por seguridad.\", file=sys.stderr)\n",
    "            print(\"2. Debes habilitar la API 'Generative Language API' en tu proyecto de Google Cloud.\", file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "# --- ¬°FUNCI√ìN MODIFICADA! ---\n",
    "def cortar_video_clips(video_local_path, secciones, captions_obj):\n",
    "    \"\"\"\n",
    "    Usa el video local, corta las secciones de la IA\n",
    "    y guarda un .txt con el subt√≠tulo de cada una.\n",
    "    \"\"\"\n",
    "    video_original_path = \"video_original.mp4\" # Nombre temporal\n",
    "\n",
    "    try:\n",
    "        # --- ¬°BLOQUE DE DESCARGA ELIMINADO! ---\n",
    "        # Reemplazado por una copia local\n",
    "        print(f\"Usando video local: {video_local_path}\")\n",
    "        if not os.path.exists(video_local_path):\n",
    "            raise FileNotFoundError(f\"No se pudo encontrar el video en: {video_local_path}\")\n",
    "        \n",
    "        print(f\"Copiando video a la ruta de trabajo temporal: {video_original_path}...\")\n",
    "        shutil.copy(video_local_path, video_original_path)\n",
    "        print(\"Copia completada.\")\n",
    "        # --- FIN DE LA MODIFICACI√ìN ---\n",
    "\n",
    "        output_folder = \"shorts_generados_por_ia\"\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "\n",
    "        for seccion in secciones:\n",
    "            nombre = seccion['nombre']\n",
    "            inicio_str = seccion['inicio']\n",
    "            fin_str = seccion['fin']\n",
    "\n",
    "            video = None\n",
    "            clip_original = None\n",
    "            clip_recortado = None\n",
    "\n",
    "            try:\n",
    "                # Esta parte funciona igual, ya que usa el archivo temporal\n",
    "                video = VideoFileClip(video_original_path)\n",
    "\n",
    "                inicio_seg = to_seconds(inicio_str)\n",
    "                fin_seg = to_seconds(fin_str)\n",
    "\n",
    "                if fin_seg > video.duration:\n",
    "                    print(f\"Advertencia: Tiempo final '{fin_str}' excede duraci√≥n. Cortando al final del video.\")\n",
    "                    fin_seg = video.duration\n",
    "\n",
    "                if inicio_seg >= fin_seg:\n",
    "                    print(f\"Advertencia: Tiempo de inicio '{inicio_str}' es mayor o igual al de fin '{fin_str}'. Saltando clip.\")\n",
    "                    continue\n",
    "\n",
    "                print(f\"Creando clip IA: {nombre} ({inicio_str} a {fin_str})...\")\n",
    "\n",
    "                clip_original = video.subclip(inicio_seg, fin_seg)\n",
    "\n",
    "                (w, h) = clip_original.size\n",
    "                target_width = h * 9 / 16\n",
    "                x_center = w / 2\n",
    "                x1 = x_center - (target_width / 2)\n",
    "                x2 = x_center + (target_width / 2)\n",
    "                clip_recortado = clip_original.crop(x1=x1, y1=0, x2=x2, y2=h)\n",
    "\n",
    "                output_path = os.path.join(output_folder, f\"{nombre}.mp4\")\n",
    "                clip_recortado.write_videofile(output_path,\n",
    "                                              codec=\"libx264\",\n",
    "                                              audio_codec=\"aac\",\n",
    "                                              logger=None)\n",
    "\n",
    "                print(f\"Clip '{nombre}' creado exitosamente.\")\n",
    "\n",
    "                # --- L√≥gica para guardar .txt (sin cambios) ---\n",
    "                texto_del_short = []\n",
    "                if captions_obj:\n",
    "                    for caption in captions_obj:\n",
    "                        if caption.start_in_seconds < fin_seg and caption.end_in_seconds > inicio_seg:\n",
    "                            clean_text = caption.text.strip().replace('\\n', ' ')\n",
    "                            texto_del_short.append(clean_text)\n",
    "\n",
    "                texto_completo = \"\\n\".join(texto_del_short)\n",
    "                txt_output_path = os.path.join(output_folder, f\"{nombre}.txt\")\n",
    "\n",
    "                try:\n",
    "                    with open(txt_output_path, 'w', encoding='utf-8') as f:\n",
    "                        f.write(texto_completo)\n",
    "                    print(f\"Texto del clip '{nombre}' guardado en .txt.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Advertencia: No se pudo guardar el .txt para '{nombre}': {e}\")\n",
    "                # --- FIN DE LA SECCI√ìN ---\n",
    "\n",
    "            finally:\n",
    "                if clip_recortado: clip_recortado.close()\n",
    "                if clip_original: clip_original.close()\n",
    "                if video: video.close()\n",
    "        \n",
    "        # Limpiamos el video temporal copiado\n",
    "        os.remove(video_original_path)\n",
    "        print(f\"\\n¬°Proceso completado! Los shorts y .txt est√°n en la carpeta '{output_folder}'.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ha ocurrido un error al cortar los clips: {e}\", file=sys.stderr)\n",
    "        if os.path.exists(video_original_path):\n",
    "            os.remove(video_original_path)\n",
    "\n",
    "# --- Configuraci√≥n Principal (Orquestador) ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # --- ¬°EDITA ESTAS L√çNEAS! ---\n",
    "    # Debes proporcionar la ruta a TUS archivos locales\n",
    "    RUTA_VIDEO_LOCAL = \"to_edit/video.mp4\"\n",
    "    RUTA_SUBTITULOS_LOCAL = \"to_edit/subs.vtt\"\n",
    "    # -----------------------------------\n",
    "\n",
    "    API_KEY = os.getenv(\"API_KEY\")\n",
    "\n",
    "    # --- ¬°CORREGIDO! ---\n",
    "    # Comprobando la variable \"API_KEY\" (en lugar de \"GEMINI_API_KEY\")\n",
    "    if not API_KEY:\n",
    "        print(\"Error: No se encontr√≥ la variable de entorno 'API_KEY'.\", file=sys.stderr)\n",
    "        print(\"Por favor, config√∫rala antes de ejecutar el script.\", file=sys.stderr)\n",
    "        print(\" (Recuerda crear un archivo .env o exportarla en tu terminal)\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    # --- ¬°NUEVO! Comprobaci√≥n de archivos locales (Corregida) ---\n",
    "\n",
    "    # Simplemente comprueba si la ruta NO existe.\n",
    "    if not os.path.exists(RUTA_VIDEO_LOCAL):\n",
    "        print(f\"Error: El archivo de video NO se encuentra en la ruta especificada:\", file=sys.stderr)\n",
    "        print(f\"{RUTA_VIDEO_LOCAL}\", file=sys.stderr)\n",
    "        print(\"Por favor, verifica que la variable RUTA_VIDEO_LOCAL sea correcta.\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    if not os.path.exists(RUTA_SUBTITULOS_LOCAL):\n",
    "        print(f\"Error: El archivo de subt√≠tulos NO se encuentra en la ruta especificada:\", file=sys.stderr)\n",
    "        print(f\"{RUTA_SUBTITULOS_LOCAL}\", file=sys.stderr)\n",
    "        print(\"Por favor, verifica que la variable RUTA_SUBTITULOS_LOCAL sea correcta.\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "        \n",
    "    # Si el script llega aqu√≠, es porque los encontr√≥.\n",
    "    print(\"¬°√âxito! Archivos de video y subt√≠tulos encontrados.\")\n",
    "    # ---------------------------------\n",
    "\n",
    "    try:\n",
    "        # --- ¬°MODIFICADO! ---\n",
    "        transcripcion, subtitulos_obj = leer_subtitulos_locales(RUTA_SUBTITULOS_LOCAL)\n",
    "\n",
    "        if not transcripcion or not subtitulos_obj:\n",
    "            raise Exception(\"No se pudo obtener la transcripci√≥n o los subt√≠tulos.\")\n",
    "\n",
    "        secciones_ai = obtener_clips_con_gemini(API_KEY, transcripcion)\n",
    "        if not secciones_ai:\n",
    "            raise Exception(\"Gemini no devolvi√≥ secciones v√°lidas.\")\n",
    "\n",
    "        print(\"\\n--- Secciones identificadas por Gemini ---\")\n",
    "        print(json.dumps(secciones_ai, indent=2, ensure_ascii=False))\n",
    "        print(\"------------------------------------------\\n\")\n",
    "\n",
    "        # --- ¬°MODIFICADO! ---\n",
    "        cortar_video_clips(RUTA_VIDEO_LOCAL, secciones_ai, subtitulos_obj)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"El proceso fall√≥: {e}\", file=sys.stderr)\n",
    "        sys.exit(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
