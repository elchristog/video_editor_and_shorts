{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "057959d8",
   "metadata": {},
   "source": [
    "# Editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd3efc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo archivo de subtÃ­tulos local: to_edit/subs.vtt...\n",
      "SubtÃ­tulos leÃ­dos y formateados exitosamente.\n",
      "Conectando con Gemini para analizar relleno verbal (duraciÃ³n > 0.1s)...\n",
      "AnÃ¡lisis de IA completado. Parseando y filtrando segmentos...\n",
      "  Â· Descartando corte de IA (duraciÃ³n invÃ¡lida o muy corta): {'motivo': 'muletilla', 'inicio': '00:02:04', 'fin': '00:02:04'}\n",
      "  Â· Descartando corte de IA (duraciÃ³n invÃ¡lida o muy corta): {'motivo': 'muletilla', 'inicio': '00:02:33', 'fin': '00:02:33'}\n",
      "  Â· Descartando corte de IA (duraciÃ³n invÃ¡lida o muy corta): {'motivo': 'muletilla', 'inicio': '00:02:36', 'fin': '00:02:36'}\n",
      "  Â· Descartando corte de IA (duraciÃ³n invÃ¡lida o muy corta): {'motivo': 'muletilla', 'inicio': '00:02:48', 'fin': '00:02:48'}\n",
      "  Â· Descartando corte de IA (duraciÃ³n invÃ¡lida o muy corta): {'motivo': 'muletilla', 'inicio': '00:03:13', 'fin': '00:03:13'}\n",
      "  Â· Descartando corte de IA (duraciÃ³n invÃ¡lida o muy corta): {'motivo': 'muletilla', 'inicio': '00:04:04', 'fin': '00:04:04'}\n",
      "  Â· Descartando corte de IA (duraciÃ³n invÃ¡lida o muy corta): {'motivo': 'muletilla', 'inicio': '00:05:07', 'fin': '00:05:07'}\n",
      "  Â· Descartando corte de IA (duraciÃ³n invÃ¡lida o muy corta): {'motivo': 'muletilla', 'inicio': '00:10:25', 'fin': '00:10:25'}\n",
      "  Â· Descartando corte de IA (duraciÃ³n invÃ¡lida o muy corta): {'motivo': 'muletilla', 'inicio': '00:10:33', 'fin': '00:10:33'}\n",
      "  Â· Descartando corte de IA (duraciÃ³n invÃ¡lida o muy corta): {'motivo': 'muletilla', 'inicio': '00:11:02', 'fin': '00:11:02'}\n",
      "  Â· Descartando corte de IA (duraciÃ³n invÃ¡lida o muy corta): {'motivo': 'muletilla', 'inicio': '00:11:19', 'fin': '00:11:19'}\n",
      "  Â· Descartando corte de IA (duraciÃ³n invÃ¡lida o muy corta): {'motivo': 'muletilla', 'inicio': '00:11:23', 'fin': '00:11:23'}\n",
      "  Â· Descartando corte de IA (duraciÃ³n invÃ¡lida o muy corta): {'motivo': 'muletilla', 'inicio': '00:12:01', 'fin': '00:12:01'}\n",
      "Se identificaron 7 cortes de IA vÃ¡lidos (duraciÃ³n >= 0.1s).\n",
      "Identificando silencios de mÃ¡s de 1.5 segundos...\n",
      "\n",
      "--- Segmentos totales a eliminar (antes de fusiÃ³n) ---\n",
      "[\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:00:13\",\n",
      "    \"fin\": \"00:00:15\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:00:36\",\n",
      "    \"fin\": \"00:00:38\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:01:19\",\n",
      "    \"fin\": \"00:01:20\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:04:06\",\n",
      "    \"fin\": \"00:04:08\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:05:04\",\n",
      "    \"fin\": \"00:05:06\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:10:36\",\n",
      "    \"fin\": \"00:10:37\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:11:07\",\n",
      "    \"fin\": \"00:11:08\"\n",
      "  }\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "Usando video local: to_edit/video.mp4\n",
      "Copiando video a la ruta de trabajo temporal: video_original_para_editar.mp4...\n",
      "Copia completada.\n",
      "Video listo para procesar.\n",
      "\n",
      "--- Segmentos a ELIMINAR (final, despuÃ©s de fusiÃ³n) ---\n",
      "[\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:00:13\",\n",
      "    \"fin\": \"00:00:15\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:00:36\",\n",
      "    \"fin\": \"00:00:38\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:01:19\",\n",
      "    \"fin\": \"00:01:20\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:04:06\",\n",
      "    \"fin\": \"00:04:08\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:05:04\",\n",
      "    \"fin\": \"00:05:06\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:10:36\",\n",
      "    \"fin\": \"00:10:37\"\n",
      "  },\n",
      "  {\n",
      "    \"motivo\": \"muletilla\",\n",
      "    \"inicio\": \"00:11:07\",\n",
      "    \"fin\": \"00:11:08\"\n",
      "  }\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "Manteniendo clip: 00:00:00 a 00:00:13\n",
      "Manteniendo clip: 00:00:15 a 00:00:36\n",
      "Manteniendo clip: 00:00:38 a 00:01:19\n",
      "Manteniendo clip: 00:01:20 a 00:04:06\n",
      "Manteniendo clip: 00:04:08 a 00:05:04\n",
      "Manteniendo clip: 00:05:06 a 00:10:36\n",
      "Manteniendo clip: 00:10:37 a 00:11:07\n",
      "Manteniendo clip final: 00:11:08 a 00:12:18\n",
      "\n",
      "Ensamblando video final a partir de 8 clips...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 520\u001b[39m\n\u001b[32m    517\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--------------------------------------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    519\u001b[39m \u001b[38;5;66;03m# ETAPA 1.5: ENSAMBLAR VIDEO BASE (Modificado)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m ruta_video_cortado = \u001b[43mensamblar_video_editado\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRUTA_VIDEO_LOCAL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtodos_los_cortes\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# <-- Â¡MODIFICADO!\u001b[39;00m\n\u001b[32m    522\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ruta_video_cortado:\n\u001b[32m    523\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mFallÃ³ la etapa de corte de video.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 338\u001b[39m, in \u001b[36mensamblar_video_editado\u001b[39m\u001b[34m(video_local_path, secciones_para_eliminar)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mEnsamblando video final a partir de \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(clips_buenos)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m clips...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    337\u001b[39m final_video = concatenate_videoclips(clips_buenos)\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[43mfinal_video\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_videofile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_final_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcodec\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlibx264\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio_codec\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maac\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[38;5;66;03m# 6. Limpieza (LÃ³gica sin cambios)\u001b[39;00m\n\u001b[32m    341\u001b[39m final_video.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<decorator-gen-74>:2\u001b[39m, in \u001b[36mwrite_videofile\u001b[39m\u001b[34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, logger)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/video_editor_and_shorts/.venv/lib/python3.11/site-packages/moviepy/decorators.py:54\u001b[39m, in \u001b[36mrequires_duration\u001b[39m\u001b[34m(f, clip, *a, **k)\u001b[39m\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAttribute \u001b[39m\u001b[33m'\u001b[39m\u001b[33mduration\u001b[39m\u001b[33m'\u001b[39m\u001b[33m not set\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<decorator-gen-73>:2\u001b[39m, in \u001b[36mwrite_videofile\u001b[39m\u001b[34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, logger)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/video_editor_and_shorts/.venv/lib/python3.11/site-packages/moviepy/decorators.py:135\u001b[39m, in \u001b[36muse_clip_fps_by_default\u001b[39m\u001b[34m(f, clip, *a, **k)\u001b[39m\n\u001b[32m    130\u001b[39m new_a = [fun(arg) \u001b[38;5;28;01mif\u001b[39;00m (name==\u001b[33m'\u001b[39m\u001b[33mfps\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m arg\n\u001b[32m    131\u001b[39m          \u001b[38;5;28;01mfor\u001b[39;00m (arg, name) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(a, names)]\n\u001b[32m    132\u001b[39m new_kw = {k: fun(v) \u001b[38;5;28;01mif\u001b[39;00m k==\u001b[33m'\u001b[39m\u001b[33mfps\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m v\n\u001b[32m    133\u001b[39m          \u001b[38;5;28;01mfor\u001b[39;00m (k,v) \u001b[38;5;129;01min\u001b[39;00m k.items()}\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mnew_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mnew_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<decorator-gen-72>:2\u001b[39m, in \u001b[36mwrite_videofile\u001b[39m\u001b[34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, logger)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/video_editor_and_shorts/.venv/lib/python3.11/site-packages/moviepy/decorators.py:22\u001b[39m, in \u001b[36mconvert_masks_to_RGB\u001b[39m\u001b[34m(f, clip, *a, **k)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m clip.ismask:\n\u001b[32m     21\u001b[39m     clip = clip.to_RGB()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/video_editor_and_shorts/.venv/lib/python3.11/site-packages/moviepy/video/VideoClip.py:300\u001b[39m, in \u001b[36mVideoClip.write_videofile\u001b[39m\u001b[34m(self, filename, fps, codec, bitrate, audio, audio_fps, preset, audio_nbytes, audio_codec, audio_bitrate, audio_bufsize, temp_audiofile, rewrite_audio, remove_temp, write_logfile, verbose, threads, ffmpeg_params, logger)\u001b[39m\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m make_audio:\n\u001b[32m    293\u001b[39m     \u001b[38;5;28mself\u001b[39m.audio.write_audiofile(audiofile, audio_fps,\n\u001b[32m    294\u001b[39m                                audio_nbytes, audio_bufsize,\n\u001b[32m    295\u001b[39m                                audio_codec, bitrate=audio_bitrate,\n\u001b[32m    296\u001b[39m                                write_logfile=write_logfile,\n\u001b[32m    297\u001b[39m                                verbose=verbose,\n\u001b[32m    298\u001b[39m                                logger=logger)\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m \u001b[43mffmpeg_write_video\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcodec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mbitrate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbitrate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mpreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mwrite_logfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwrite_logfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    304\u001b[39m \u001b[43m                   \u001b[49m\u001b[43maudiofile\u001b[49m\u001b[43m=\u001b[49m\u001b[43maudiofile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthreads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mffmpeg_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mffmpeg_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remove_temp \u001b[38;5;129;01mand\u001b[39;00m make_audio:\n\u001b[32m    310\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(audiofile):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/video_editor_and_shorts/.venv/lib/python3.11/site-packages/moviepy/video/io/ffmpeg_writer.py:228\u001b[39m, in \u001b[36mffmpeg_write_video\u001b[39m\u001b[34m(clip, filename, fps, codec, bitrate, preset, withmask, write_logfile, audiofile, verbose, threads, ffmpeg_params, logger)\u001b[39m\n\u001b[32m    225\u001b[39m                 mask = mask.astype(\u001b[33m\"\u001b[39m\u001b[33muint8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    226\u001b[39m             frame = np.dstack([frame,mask])\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m         \u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m write_logfile:\n\u001b[32m    231\u001b[39m     logfile.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/video_editor_and_shorts/.venv/lib/python3.11/site-packages/moviepy/video/io/ffmpeg_writer.py:136\u001b[39m, in \u001b[36mFFMPEG_VideoWriter.write_frame\u001b[39m\u001b[34m(self, img_array)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m PY3:\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m        \u001b[38;5;28mself\u001b[39m.proc.stdin.write(img_array.tobytes())\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    138\u001b[39m        \u001b[38;5;28mself\u001b[39m.proc.stdin.write(img_array.tostring())\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import webvtt\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "import sys\n",
    "# Â¡RESTAURADO! Esta es la forma 100% correcta de importar.\n",
    "from moviepy.editor import VideoFileClip, concatenate_videoclips, TextClip, CompositeVideoClip\n",
    "from io import StringIO\n",
    "import requests\n",
    "import shutil # <-- Â¡NUEVO IMPORT! Necesario para copiar tu video\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# --- FUNCIONES DE TIEMPO (SIN CAMBIOS) ---\n",
    "def to_seconds(time_str):\n",
    "    \"\"\"Convierte un string de tiempo 'HH:MM:SS' o 'MM:SS' a segundos.\"\"\"\n",
    "    try:\n",
    "        time_str = time_str.split('.')[0]\n",
    "        parts = list(map(int, time_str.split(':')))\n",
    "        if len(parts) == 3:  # HH:MM:SS\n",
    "            h, m, s = parts\n",
    "            return h * 3600 + m * 60 + s\n",
    "        elif len(parts) == 2:  # MM:SS\n",
    "            m, s = parts\n",
    "            return m * 60 + s\n",
    "        else:\n",
    "            raise ValueError(\"Formato de tiempo no vÃ¡lido\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error al convertir tiempo '{time_str}': {e}\", file=sys.stderr)\n",
    "        return 0\n",
    "\n",
    "def from_seconds(total_seconds):\n",
    "    \"\"\"Convierte segundos a un string de tiempo 'HH:MM:SS'.\"\"\"\n",
    "    h = int(total_seconds // 3600)\n",
    "    m = int((total_seconds % 3600) // 60)\n",
    "    s = int(total_seconds % 60)\n",
    "    return f\"{h:02}:{m:02}:{s:02}\"\n",
    "\n",
    "# --- FUNCIÃ“N UTILITARIA PARA DESCARGAR FUENTE DE EMOJIS (SIN CAMBIOS) ---\n",
    "def descargar_fuente_emoji(font_path=\"NotoColorEmoji.ttf\"):\n",
    "    \"\"\"\n",
    "    Descarga la fuente Noto Color Emoji si no existe,\n",
    "    necesaria para que moviepy renderice emojis.\n",
    "    \"\"\"\n",
    "    if os.path.exists(font_path):\n",
    "        print(f\"Fuente de emoji encontrada: {font_path}\")\n",
    "        return font_path\n",
    "\n",
    "    print(\"Descargando fuente de emoji (NotoColorEmoji.ttf)...\")\n",
    "    url = \"https://github.com/googlefonts/noto-emoji/raw/main/fonts/NotoColorEmoji.ttf\"\n",
    "    try:\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        r.raise_for_status()\n",
    "        with open(font_path, 'wb') as f:\n",
    "            f.write(r.content)\n",
    "        print(\"Fuente de emoji descargada exitosamente.\")\n",
    "        return font_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error descargando la fuente de emoji: {e}\", file=sys.stderr)\n",
    "        print(\"Los emojis podrÃ­an no renderizarse correctamente.\", file=sys.stderr)\n",
    "        return None # Retorna None si falla\n",
    "\n",
    "# --- FUNCIÃ“N DE SUBTÃTULOS (MODIFICADA PARA LEER ARCHIVO LOCAL) ---\n",
    "def leer_subtitulos_locales(vtt_path): # <-- Â¡MODIFICADO! Cambia el argumento\n",
    "    \"\"\"\n",
    "    Lee un archivo .vtt local y lo devuelve\n",
    "    como un texto formateado Y como un objeto webvtt.\n",
    "    \"\"\"\n",
    "    captions = None\n",
    "    transcript = \"\"\n",
    "    try:\n",
    "        # <-- Â¡TODA ESTA SECCIÃ“N FUE MODIFICADA! ---\n",
    "        print(f\"Leyendo archivo de subtÃ­tulos local: {vtt_path}...\")\n",
    "        if not os.path.exists(vtt_path):\n",
    "            raise FileNotFoundError(f\"No se pudo encontrar el archivo de subtÃ­tulos en: {vtt_path}\")\n",
    "\n",
    "        with open(vtt_path, 'r', encoding='utf-8') as f:\n",
    "            vtt_content = f.read()\n",
    "        # --- FIN DE LA MODIFICACIÃ“N ---\n",
    "\n",
    "        captions = webvtt.read_buffer(StringIO(vtt_content))\n",
    "        for caption in captions:\n",
    "            timestamp = caption.start\n",
    "            timestamp_clean = timestamp.split('.')[0]\n",
    "            transcript += f\"[{timestamp_clean}] {caption.text.strip().replace(chr(10), ' ')}\\n\"\n",
    "        \n",
    "        print(f\"SubtÃ­tulos leÃ­dos y formateados exitosamente.\")\n",
    "        return transcript, captions\n",
    "    except Exception as e:\n",
    "        print(f\"Error leyendo o procesando el archivo VTT: {e}\", file=sys.stderr)\n",
    "        return None, None\n",
    "    # No hay 'finally' para borrar, ya que es el archivo original del usuario\n",
    "\n",
    "# --- FUNCIÃ“N DE IA (CORTES) (SIN CAMBIOS) ---\n",
    "def obtener_cortes_para_eliminar(api_key, transcripcion, duracion_minima_seg=0.1):\n",
    "    \"\"\"\n",
    "    Toma la transcripcion (variable con 'c') y la pasa a la IA.\n",
    "    Internamente la llama 'transcript' (variable con 't'), pero eso es correcto.\n",
    "    \"\"\"\n",
    "    print(f\"Conectando con Gemini para analizar relleno verbal (duraciÃ³n > {duracion_minima_seg}s)...\")\n",
    "    try:\n",
    "        genai.configure(api_key=api_key)\n",
    "        model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "        prompt = f\"\"\"\n",
    "        Eres un editor de video cuya tarea es eliminar \"relleno\" obvio\n",
    "        de una transcripciÃ³n.\n",
    "\n",
    "        Analiza la siguiente transcripciÃ³n e identifica segmentos para ELIMINAR\n",
    "        basado en dos criterios. SÃ© conservador.\n",
    "\n",
    "        CRITERIOS PARA ELIMINAR:\n",
    "        1.  **Muletillas / Rellenos:** Palabras o sonidos como 'ehh', 'mmm',\n",
    "            'pues...', 'esteee...', 'o sea...', 'bueno...'.\n",
    "            Tu objetivo es eliminar las que *interrumpen la fluidez*.\n",
    "        2.  **Reinicios Falsos CLAROS:** Oraciones que el orador\n",
    "            empieza, abandona a mitad de frase, y vuelve a empezar\n",
    "            (ej. \"Y el video... no, mejor dicho, el audio...\")\n",
    "\n",
    "        REGLAS CRÃTICAS:\n",
    "        -   **NO ELIMINES NADA POR 'REPETICIÃ“N'.**\n",
    "        -   **SÃ‰ CONSERVADOR.** Si dudas, NO LO CORTES.\n",
    "        -   Si el video estÃ¡ limpio, devuelve una lista vacÃ­a [].\n",
    "\n",
    "        Tu respuesta DEBE ser Ãºnicamente un objeto JSON:\n",
    "        - \"motivo\": (\"muletilla\", \"reinicio falso\")\n",
    "        - \"inicio\": El timestamp 'HH:MM:SS' de inicio.\n",
    "        - \"fin\": El timestamp 'HH:MM:SS' de fin.\n",
    "\n",
    "        Ejemplo de respuesta:\n",
    "        [\n",
    "          {{\"motivo\": \"muletilla\", \"inicio\": \"00:02:15\", \"fin\": \"00:02:17\"}}\n",
    "        ]\n",
    "\n",
    "        AquÃ­ estÃ¡ la transcripciÃ³n:\n",
    "        ---\n",
    "        {transcripcion}\n",
    "        ---\n",
    "        \"\"\"\n",
    "        response = model.generate_content(prompt)\n",
    "        cleaned_response = response.text.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "        print(\"AnÃ¡lisis de IA completado. Parseando y filtrando segmentos...\")\n",
    "        secciones = json.loads(cleaned_response)\n",
    "\n",
    "        secciones_filtradas = []\n",
    "        for s in secciones:\n",
    "            try:\n",
    "                inicio_seg = to_seconds(s['inicio'])\n",
    "                fin_seg = to_seconds(s['fin'])\n",
    "                duracion_corte = fin_seg - inicio_seg\n",
    "                if duracion_corte > 0 and duracion_corte >= duracion_minima_seg:\n",
    "                    secciones_filtradas.append(s)\n",
    "                else:\n",
    "                    print(f\"  Â· Descartando corte de IA (duraciÃ³n invÃ¡lida o muy corta): {s}\")\n",
    "            except Exception:\n",
    "                pass # Ignorar cortes malformados\n",
    "\n",
    "        print(f\"Se identificaron {len(secciones_filtradas)} cortes de IA vÃ¡lidos (duraciÃ³n >= {duracion_minima_seg}s).\")\n",
    "        return secciones_filtradas\n",
    "    except Exception as e:\n",
    "        print(f\"Error al contactar con Gemini o parsear JSON: {e}\", file=sys.stderr)\n",
    "        return []\n",
    "\n",
    "# --- FUNCIÃ“N DE IA PARA EMOJIS (Â¡CORREGIDA!) ---\n",
    "def obtener_emojis_para_subtitulos(api_key, captions_obj, secciones_para_eliminar):\n",
    "    \"\"\"\n",
    "    Filtra los subtÃ­tulos buenos y pide a Gemini que sugiera emojis para ellos.\n",
    "    \"\"\"\n",
    "    print(\"Conectando con Gemini para analizar y sugerir emojis...\")\n",
    "    if not captions_obj:\n",
    "        return []\n",
    "\n",
    "    # 1. Pre-procesar las secciones a eliminar para una bÃºsqueda rÃ¡pida\n",
    "    cortes_seg = []\n",
    "    for corte in secciones_para_eliminar:\n",
    "        try:\n",
    "            cortes_seg.append((to_seconds(corte['inicio']), to_seconds(corte['fin'])))\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    # 2. Filtrar solo los subtÃ­tulos que NO estÃ¡n en una secciÃ³n eliminada\n",
    "    captions_buenos = []\n",
    "    transcript_buena = \"\"\n",
    "    for cap in captions_obj:\n",
    "        es_bueno = True\n",
    "        for inicio, fin in cortes_seg:\n",
    "            if cap.start_in_seconds >= inicio and cap.start_in_seconds < fin:\n",
    "                es_bueno = False\n",
    "                break\n",
    "        if es_bueno:\n",
    "            captions_buenos.append(cap)\n",
    "            timestamp_clean = cap.start.split('.')[0]\n",
    "            transcript_buena += f\"[{timestamp_clean}] {cap.text.strip().replace(chr(10), ' ')}\\n\"\n",
    "\n",
    "    if not transcript_buena:\n",
    "        print(\"No se encontrÃ³ transcripciÃ³n vÃ¡lida despuÃ©s del filtrado.\")\n",
    "        return []\n",
    "\n",
    "    # 3. Enviar la transcripciÃ³n \"buena\" a Gemini\n",
    "    try:\n",
    "        genai.configure(api_key=api_key)\n",
    "        model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "        prompt = f\"\"\"\n",
    "        Eres un editor de video creativo. Analiza la siguiente transcripciÃ³n\n",
    "        e identifica palabras o frases clave que puedan ser realzadas\n",
    "        con un emoji relevante.\n",
    "\n",
    "        REGLAS:\n",
    "        1.  SÃ© selectivo. No aÃ±adas emojis a cada lÃ­nea, solo a\n",
    "            conceptos visuales fuertes (ej. idea ðŸ’¡, dinero ðŸ’°,\n",
    "            rÃ¡pido ðŸš€, mundo ðŸŒ, amor â¤ï¸, Ã©xito ðŸ†).\n",
    "        2.  El emoji debe aparecer durante la palabra clave.\n",
    "        3.  El \"fin\" debe ser 1 o 2 segundos despuÃ©s del \"inicio\".\n",
    "        4.  Usa los timestamps originales del texto.\n",
    "\n",
    "        Tu respuesta DEBE ser Ãºnicamente un objeto JSON (una lista de objetos):\n",
    "        - \"emoji\": El emoji unicode (ej. \"ðŸ’¡\").\n",
    "        - \"inicio\": El timestamp 'HH:MM:SS' de inicio.\n",
    "        - \"fin\": El timestamp 'HH:MM:SS' de fin.\n",
    "\n",
    "        Ejemplo de respuesta:\n",
    "        [\n",
    "          {{\"emoji\": \"ðŸ’¡\", \"inicio\": \"00:02:15\", \"fin\": \"00:02:17\"}},\n",
    "          {{\"emoji\": \"ðŸ’°\", \"inicio\": \"00:05:31\", \"fin\": \"00:05:33\"}}\n",
    "        ]\n",
    "\n",
    "        AquÃ­ estÃ¡ la transcripciÃ³n:\n",
    "        ---\n",
    "        {transcript_buena}\n",
    "        ---\n",
    "        \"\"\"\n",
    "        response = model.generate_content(prompt)\n",
    "        cleaned_response = response.text.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "        print(\"AnÃ¡lisis de emojis completado.\")\n",
    "        return json.loads(cleaned_response)\n",
    "    except Exception as e:\n",
    "        print(f\"Error al contactar con Gemini para emojis: {e}\", file=sys.stderr)\n",
    "        return []\n",
    "\n",
    "# --- FUNCIÃ“N DE SILENCIOS (SIN CAMBIOS) ---\n",
    "def identificar_silencios_largos(captions_obj, umbral_segundos=2.0):\n",
    "    print(f\"Identificando silencios de mÃ¡s de {umbral_segundos} segundos...\")\n",
    "    if not captions_obj:\n",
    "        return []\n",
    "    silencios = []\n",
    "    sorted_captions = sorted(captions_obj, key=lambda c: c.start_in_seconds)\n",
    "    for i in range(len(sorted_captions) - 1):\n",
    "        cap_actual = sorted_captions[i]\n",
    "        cap_siguiente = sorted_captions[i+1]\n",
    "        gap = cap_siguiente.start_in_seconds - cap_actual.end_in_seconds\n",
    "        if gap >= umbral_segundos:\n",
    "            print(f\"  Â· Silencio largo detectado: {from_seconds(cap_actual.end_in_seconds)} a {from_seconds(cap_siguiente.start_in_seconds)}\")\n",
    "            silencios.append({\n",
    "                \"motivo\": \"silencio largo\",\n",
    "                \"inicio\": from_seconds(cap_actual.end_in_seconds),\n",
    "                \"fin\": from_seconds(cap_siguiente.start_in_seconds)\n",
    "            })\n",
    "    return silencios\n",
    "\n",
    "# --- FUNCIÃ“N DE ENSAMBLAJE (MODIFICADA PARA USAR ARCHIVO LOCAL) ---\n",
    "def ensamblar_video_editado(video_local_path, secciones_para_eliminar): # <-- Â¡MODIFICADO!\n",
    "    \"\"\"\n",
    "    Usa un video local y lo ensambla.\n",
    "    Devuelve la RUTA al video final si tiene Ã©xito.\n",
    "    \"\"\"\n",
    "    video_original_path = \"video_original_para_editar.mp4\"\n",
    "    # --- Â¡MODIFICADO! ---\n",
    "    video_final_path = os.path.join(\"edited\", \"video_final_editado.mp4\") # Video base cortado\n",
    "    try:\n",
    "        \n",
    "        # <-- Â¡TODA ESTA SECCIÃ“N FUE MODIFICADA! ---\n",
    "        # Se eliminÃ³ la descarga de yt-dlp.\n",
    "        print(f\"Usando video local: {video_local_path}\")\n",
    "        if not os.path.exists(video_local_path):\n",
    "            raise FileNotFoundError(f\"No se pudo encontrar el archivo de video en: {video_local_path}\")\n",
    "        \n",
    "        # Copiar el video a la ruta de trabajo que el script espera\n",
    "        print(f\"Copiando video a la ruta de trabajo temporal: {video_original_path}...\")\n",
    "        shutil.copy(video_local_path, video_original_path)\n",
    "        print(\"Copia completada.\")\n",
    "        # --- FIN DE LA MODIFICACIÃ“N ---\n",
    "\n",
    "\n",
    "        print(\"Video listo para procesar.\")\n",
    "        video = VideoFileClip(video_original_path)\n",
    "        video_duration = video.duration\n",
    "        if not secciones_para_eliminar:\n",
    "            print(\"No se especificaron cortes. El video no serÃ¡ modificado.\")\n",
    "            video.close()\n",
    "            # Renombramos el archivo copiado para que sirva como \"editado\"\n",
    "            if os.path.exists(video_original_path):\n",
    "                os.rename(video_original_path, video_final_path)\n",
    "            return video_final_path # Devuelve la ruta\n",
    "\n",
    "        # 1. Ordenar y fusionar cortes (LÃ³gica sin cambios)\n",
    "        cortes_ordenados = sorted(secciones_para_eliminar, key=lambda x: to_seconds(x['inicio']))\n",
    "        cortes_fusionados = []\n",
    "        if cortes_ordenados:\n",
    "            current_merged_corte = cortes_ordenados[0]\n",
    "            for i in range(1, len(cortes_ordenados)):\n",
    "                next_corte = cortes_ordenados[i]\n",
    "                current_fin_seg = to_seconds(current_merged_corte['fin'])\n",
    "                next_inicio_seg = to_seconds(next_corte['inicio'])\n",
    "                if next_inicio_seg <= current_fin_seg + 0.1:\n",
    "                    current_merged_corte['fin'] = from_seconds(max(current_fin_seg, to_seconds(next_corte['fin'])))\n",
    "                else:\n",
    "                    cortes_fusionados.append(current_merged_corte)\n",
    "                    current_merged_corte = next_corte\n",
    "            cortes_fusionados.append(current_merged_corte)\n",
    "        print(\"\\n--- Segmentos a ELIMINAR (final, despuÃ©s de fusiÃ³n) ---\")\n",
    "        print(json.dumps(cortes_fusionados, indent=2, ensure_ascii=False))\n",
    "        print(\"--------------------------------------------------\\n\")\n",
    "\n",
    "        # 2. Crear lista de clips \"buenos\" (LÃ³gica sin cambios)\n",
    "        clips_buenos = []\n",
    "        current_time_seg = 0.0\n",
    "        for corte in cortes_fusionados:\n",
    "            inicio_corte_seg = to_seconds(corte['inicio'])\n",
    "            fin_corte_seg = to_seconds(corte['fin'])\n",
    "            if fin_corte_seg > video_duration: fin_corte_seg = video_duration\n",
    "            if inicio_corte_seg > current_time_seg:\n",
    "                if (inicio_corte_seg - current_time_seg) > 0.1:\n",
    "                    print(f\"Manteniendo clip: {from_seconds(current_time_seg)} a {from_seconds(inicio_corte_seg)}\")\n",
    "                    clips_buenos.append(video.subclip(current_time_seg, inicio_corte_seg))\n",
    "            current_time_seg = max(current_time_seg, fin_corte_seg)\n",
    "        if (video_duration - current_time_seg) > 0.1:\n",
    "            print(f\"Manteniendo clip final: {from_seconds(current_time_seg)} a {from_seconds(video_duration)}\")\n",
    "            clips_buenos.append(video.subclip(current_time_seg, video_duration))\n",
    "\n",
    "        # 4. Concatenar (LÃ³gica sin cambios)\n",
    "        if not clips_buenos:\n",
    "            print(\"Advertencia: La lÃ³gica de cortes resultÃ³ en un video vacÃ­o.\")\n",
    "            video.close()\n",
    "            return None\n",
    "        print(f\"\\nEnsamblando video final a partir de {len(clips_buenos)} clips...\")\n",
    "        final_video = concatenate_videoclips(clips_buenos)\n",
    "        final_video.write_videofile(video_final_path, codec=\"libx264\", audio_codec=\"aac\", logger=None)\n",
    "\n",
    "        # 6. Limpieza (LÃ³gica sin cambios)\n",
    "        final_video.close()\n",
    "        for clip in clips_buenos: clip.close()\n",
    "        video.close()\n",
    "        return video_final_path # Â¡Devuelve la ruta!\n",
    "    except Exception as e:\n",
    "        print(f\"Ha ocurrido un error al ensamblar el video: {e}\", file=sys.stderr)\n",
    "        return None\n",
    "    finally:\n",
    "        # La limpieza del video original temporal sigue siendo vÃ¡lida\n",
    "        if os.path.exists(video_original_path):\n",
    "            os.remove(video_original_path)\n",
    "\n",
    "# --- FUNCIÃ“N DE COMPOSICIÃ“N DE EMOJIS (Â¡MODIFICADA!) ---\n",
    "def crear_video_con_emojis(video_base_path, video_final_path, lista_emojis, secciones_para_eliminar):\n",
    "    \"\"\"\n",
    "    Toma el video base cortado y le superpone los emojis.\n",
    "    \"\"\"\n",
    "    print(f\"Iniciando Etapa 2: SuperposiciÃ³n de Emojis en {video_base_path}...\")\n",
    "    try:\n",
    "        # 1. Descargar la fuente de emojis\n",
    "        font_path = descargar_fuente_emoji()\n",
    "        if not font_path:\n",
    "            raise Exception(\"No se pudo descargar la fuente de emojis. Abortando.\")\n",
    "\n",
    "        # 2. Cargar el video base (cortado)\n",
    "        video_base = VideoFileClip(video_base_path)\n",
    "\n",
    "        # 3. Preparar el \"mapeador de timestamps\"\n",
    "        # Esto convierte el tiempo original al nuevo tiempo (despuÃ©s de los cortes)\n",
    "        cortes_procesados = sorted(\n",
    "            [{'inicio': to_seconds(c['inicio']), 'fin': to_seconds(c['fin'])} for c in secciones_para_eliminar],\n",
    "            key=lambda x: x['inicio']\n",
    "        )\n",
    "\n",
    "        def calcular_nuevo_timestamp(tiempo_original_seg):\n",
    "            tiempo_a_restar = 0.0\n",
    "            for corte in cortes_procesados:\n",
    "                if tiempo_original_seg > corte['fin']:\n",
    "                    tiempo_a_restar += (corte['fin'] - corte['inicio'])\n",
    "                elif tiempo_original_seg > corte['inicio']:\n",
    "                    # El tiempo estÃ¡ DENTRO de un corte, ajustar al inicio del corte\n",
    "                    tiempo_a_restar += (tiempo_original_seg - corte['inicio'])\n",
    "                    break\n",
    "            return max(0, tiempo_original_seg - tiempo_a_restar)\n",
    "\n",
    "        # 4. Crear los clips de texto para cada emoji\n",
    "        clips_de_emojis = []\n",
    "        for item in lista_emojis:\n",
    "            try:\n",
    "                inicio_original = to_seconds(item['inicio'])\n",
    "                fin_original = to_seconds(item['fin'])\n",
    "                duracion = fin_original - inicio_original\n",
    "\n",
    "                if duracion <= 0.1: # Ignorar emojis de duraciÃ³n invÃ¡lida\n",
    "                    continue\n",
    "\n",
    "                # Â¡Calcular el nuevo timestamp!\n",
    "                nuevo_inicio = calcular_nuevo_timestamp(inicio_original)\n",
    "\n",
    "                # Asegurarse de que el clip no se salga del video\n",
    "                if nuevo_inicio + duracion > video_base.duration:\n",
    "                    duracion = video_base.duration - nuevo_inicio\n",
    "\n",
    "                if duracion <= 0.1:\n",
    "                    continue\n",
    "\n",
    "                print(f\"  Â· AÃ±adiendo emoji {item['emoji']} en {from_seconds(nuevo_inicio)} (Original: {item['inicio']})\")\n",
    "\n",
    "                txt_clip = TextClip(\n",
    "                    item['emoji'],\n",
    "                    fontsize=100,\n",
    "                    font=font_path,\n",
    "                    color='white', # Fallback, pero NotoColorEmoji tiene su propio color\n",
    "                    method='caption' # <-- Â¡SOLUCIÃ“N! Usar PIL en lugar de ImageMagick\n",
    "                )\n",
    "\n",
    "                txt_clip = txt_clip.set_position(('center', 0.7), relative=True) # PosiciÃ³n al 70% hacia abajo\n",
    "                txt_clip = txt_clip.set_start(nuevo_inicio)\n",
    "                txt_clip = txt_clip.set_duration(duracion)\n",
    "                txt_clip = txt_clip.fadein(0.2).fadeout(0.2) # Efecto suave\n",
    "\n",
    "                clips_de_emojis.append(txt_clip)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error procesando emoji '{item}': {e}\", file=sys.stderr)\n",
    "\n",
    "        if not clips_de_emojis:\n",
    "            print(\"No se generaron emojis. El video final es el video cortado.\")\n",
    "            video_base.close()\n",
    "            # Renombrar el archivo cortado al nombre final\n",
    "            if os.path.exists(video_base_path) and not os.path.exists(video_final_path):\n",
    "                os.rename(video_base_path, video_final_path)\n",
    "            return video_final_path\n",
    "\n",
    "        # 5. Componer el video final\n",
    "        print(f\"Componiendo video base con {len(clips_de_emojis)} emojis...\")\n",
    "        video_final_con_emojis = CompositeVideoClip([video_base] + clips_de_emojis)\n",
    "\n",
    "        video_final_con_emojis.write_videofile(\n",
    "            video_final_path,\n",
    "            codec=\"libx264\",\n",
    "            audio_codec=\"aac\",\n",
    "            logger=None\n",
    "        )\n",
    "\n",
    "        print(f\"\\nÂ¡Proceso completado! El video con emojis estÃ¡ en '{video_final_path}'.\")\n",
    "\n",
    "        # Limpieza\n",
    "        video_final_con_emojis.close()\n",
    "        video_base.close()\n",
    "        for clip in clips_de_emojis:\n",
    "            clip.close()\n",
    "\n",
    "        # <-- Â¡MODIFICADO! Limpieza del video cortado intermedio\n",
    "        if os.path.exists(video_base_path):\n",
    "             os.remove(video_base_path)\n",
    "        # --- FIN MODIFICACIÃ“N ---\n",
    "\n",
    "        return video_final_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ha ocurrido un error al crear el video con emojis: {e}\", file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "\n",
    "# --- ConfiguraciÃ³n Principal (Orquestador ACTUALIZADO) ---\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # --- Â¡NUEVO! Directorio de salida ---\n",
    "    OUTPUT_FOLDER = \"edited\"\n",
    "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "    # -----------------------------------\n",
    "\n",
    "    # --- Â¡EDITA ESTAS LÃNEAS! ---\n",
    "    # Debes proporcionar la ruta a TUS archivos locales\n",
    "    RUTA_VIDEO_LOCAL = \"to_edit/video.mp4\"\n",
    "    RUTA_SUBTITULOS_LOCAL = \"to_edit/subs.vtt\"\n",
    "    # -----------------------------------\n",
    "\n",
    "    API_KEY = os.getenv(\"API_KEY\")  # Â¡CUIDADO CON LA API KEY!\n",
    "\n",
    "    if not API_KEY or \"TU_API_KEY_AQUI\" in API_KEY: # <-- Â¡MODIFICADO! Chequeo mejorado\n",
    "        print(\"Error: No se encontrÃ³ la API_KEY.\", file=sys.stderr)\n",
    "        print(\"AsegÃºrate de tener un archivo .env con 'API_KEY=tu_clave'\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    # --- Â¡NUEVO CHEQUEO DE ARCHIVOS! ---\n",
    "    if \"AQUI_VA_LA_RUTA\" in RUTA_VIDEO_LOCAL or not os.path.exists(RUTA_VIDEO_LOCAL):\n",
    "        print(f\"Error: El archivo de video no se encuentra en '{RUTA_VIDEO_LOCAL}'\", file=sys.stderr)\n",
    "        print(\"Por favor, edita la variable RUTA_VIDEO_LOCAL en el script.\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "    if \"AQUI_VA_LA_RUTA\" in RUTA_SUBTITULOS_LOCAL or not os.path.exists(RUTA_SUBTITULOS_LOCAL):\n",
    "        print(f\"Error: El archivo de subtÃ­tulos no se encuentra en '{RUTA_SUBTITULOS_LOCAL}'\", file=sys.stderr)\n",
    "        print(\"Por favor, edita la variable RUTA_SUBTITULOS_LOCAL en el script.\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "    # ---------------------------------\n",
    "\n",
    "    try:\n",
    "        # --- Â¡NUEVO! Definir ruta de salida final ---\n",
    "        ruta_video_final_con_emojis = os.path.join(OUTPUT_FOLDER, \"video_final_con_emojis.mp4\")\n",
    "\n",
    "        # ETAPA 0: OBTENER DATOS (Modificado)\n",
    "        transcripcion, subtitulos_obj = leer_subtitulos_locales(RUTA_SUBTITULOS_LOCAL) # <-- Â¡MODIFICADO!\n",
    "        if not transcripcion or not subtitulos_obj:\n",
    "            raise Exception(\"No se pudo obtener la transcripciÃ³n o los subtÃ­tulos del archivo local.\")\n",
    "\n",
    "        # ETAPA 1: LÃ“GICA DE CORTE (Sin cambios)\n",
    "        cortes_ia = obtener_cortes_para_eliminar(API_KEY, transcripcion, duracion_minima_seg=0.1)\n",
    "        cortes_silencio = identificar_silencios_largos(subtitulos_obj, umbral_segundos=1.5)\n",
    "        todos_los_cortes = cortes_ia + cortes_silencio\n",
    "\n",
    "        if not todos_los_cortes:\n",
    "            print(\"\\nIA y anÃ¡lisis de silencios no encontraron nada que eliminar. Â¡Video limpio!\")\n",
    "        else:\n",
    "            print(\"\\n--- Segmentos totales a eliminar (antes de fusiÃ³n) ---\")\n",
    "            print(json.dumps(todos_los_cortes, indent=2, ensure_ascii=False))\n",
    "            print(\"--------------------------------------------------\\n\")\n",
    "\n",
    "        # ETAPA 1.5: ENSAMBLAR VIDEO BASE (Modificado)\n",
    "        ruta_video_cortado = ensamblar_video_editado(RUTA_VIDEO_LOCAL, todos_los_cortes) # <-- Â¡MODIFICADO!\n",
    "\n",
    "        if not ruta_video_cortado:\n",
    "            raise Exception(\"FallÃ³ la etapa de corte de video.\")\n",
    "\n",
    "        print(f\"Etapa 1 completada. Video cortado guardado en: {ruta_video_cortado}\")\n",
    "\n",
    "        # ETAPA 2: LÃ“GICA DE EMOJIS (Sin cambios)\n",
    "        lista_emojis = obtener_emojis_para_subtitulos(API_KEY, subtitulos_obj, todos_los_cortes)\n",
    "\n",
    "        if not lista_emojis:\n",
    "            print(\"IA no sugiriÃ³ emojis. El proceso ha finalizado.\")\n",
    "            # <-- Â¡MODIFICADO! Asegurarse de que el archivo final tenga el nombre correcto\n",
    "            if os.path.exists(ruta_video_cortado) and not os.path.exists(ruta_video_final_con_emojis):\n",
    "                os.rename(ruta_video_cortado, ruta_video_final_con_emojis)\n",
    "                print(f\"Video final (solo cortado) guardado como: {ruta_video_final_con_emojis}\")\n",
    "            sys.exit(0)\n",
    "        else:\n",
    "            print(\"\\n--- Emojis sugeridos por la IA ---\")\n",
    "            print(json.dumps(lista_emojis, indent=2, ensure_ascii=False))\n",
    "            print(\"------------------------------------\\n\")\n",
    "\n",
    "        # ETAPA 2.5: ENSAMBLAR VIDEO FINAL CON EMOJIS (Sin cambios)\n",
    "        # --- Â¡MODIFICADO! La ruta ya estÃ¡ definida arriba ---\n",
    "        # ruta_video_final_con_emojis = \"video_final_con_emojis.mp4\" <--- Esta lÃ­nea se elimina\n",
    "        crear_video_con_emojis(\n",
    "            ruta_video_cortado,\n",
    "            ruta_video_final_con_emojis,\n",
    "            lista_emojis,\n",
    "            todos_los_cortes\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"El proceso principal fallÃ³: {e}\", file=sys.stderr)\n",
    "        # Limpieza final en caso de error\n",
    "        if os.path.exists(\"video_original_para_editar.mp4\"):\n",
    "            os.remove(\"video_original_para_editar.mp4\")\n",
    "        if os.path.exists(\"video_final_editado.mp4\"):\n",
    "            os.remove(\"video_final_editado.mp4\")\n",
    "        sys.exit(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b166c87d",
   "metadata": {},
   "source": [
    "# Shorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51efb2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Â¡Ã‰xito! Archivos de video y subtÃ­tulos encontrados.\n",
      "Leyendo archivo de subtÃ­tulos local: to_edit/subs.vtt...\n",
      "SubtÃ­tulos leÃ­dos y formateados exitosamente.\n",
      "Conectando con Gemini para analizar momentos clave...\n",
      "AnÃ¡lisis de IA completado. Parseando secciones...\n",
      "\n",
      "--- Secciones identificadas por Gemini ---\n",
      "[\n",
      "  {\n",
      "    \"nombre\": \"Primer_Requisito_Bachelor\",\n",
      "    \"inicio\": \"00:00:35\",\n",
      "    \"fin\": \"00:01:20\"\n",
      "  },\n",
      "  {\n",
      "    \"nombre\": \"Examen_NCLEX_No_Es_Imposible\",\n",
      "    \"inicio\": \"00:05:05\",\n",
      "    \"fin\": \"00:05:42\"\n",
      "  },\n",
      "  {\n",
      "    \"nombre\": \"Visa_H1B_vs_EV3\",\n",
      "    \"inicio\": \"00:12:08\",\n",
      "    \"fin\": \"00:12:47\"\n",
      "  },\n",
      "  {\n",
      "    \"nombre\": \"Beneficios_Posgrados_Enfermeros_EEUU\",\n",
      "    \"inicio\": \"00:14:06\",\n",
      "    \"fin\": \"00:14:23\"\n",
      "  }\n",
      "]\n",
      "------------------------------------------\n",
      "\n",
      "Usando video local: to_edit/video.mp4\n",
      "Copiando video a la ruta de trabajo temporal: video_original.mp4...\n",
      "Copia completada.\n",
      "Creando clip IA: Primer_Requisito_Bachelor (00:00:35 a 00:01:20)...\n",
      "Clip 'Primer_Requisito_Bachelor' creado exitosamente.\n",
      "Texto del clip 'Primer_Requisito_Bachelor' guardado en .txt.\n",
      "Creando clip IA: Examen_NCLEX_No_Es_Imposible (00:05:05 a 00:05:42)...\n",
      "Clip 'Examen_NCLEX_No_Es_Imposible' creado exitosamente.\n",
      "Texto del clip 'Examen_NCLEX_No_Es_Imposible' guardado en .txt.\n",
      "Creando clip IA: Visa_H1B_vs_EV3 (00:12:08 a 00:12:47)...\n",
      "Clip 'Visa_H1B_vs_EV3' creado exitosamente.\n",
      "Texto del clip 'Visa_H1B_vs_EV3' guardado en .txt.\n",
      "Creando clip IA: Beneficios_Posgrados_Enfermeros_EEUU (00:14:06 a 00:14:23)...\n",
      "Clip 'Beneficios_Posgrados_Enfermeros_EEUU' creado exitosamente.\n",
      "Texto del clip 'Beneficios_Posgrados_Enfermeros_EEUU' guardado en .txt.\n",
      "\n",
      "Â¡Proceso completado! Los shorts y .txt estÃ¡n en la carpeta 'shorts_generados_por_ia'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import webvtt\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "import sys\n",
    "from moviepy.editor import VideoFileClip\n",
    "from io import StringIO\n",
    "import shutil # <-- Â¡NUEVO IMPORT!\n",
    "\n",
    "def to_seconds(time_str):\n",
    "    \"\"\"Convierte un string de tiempo 'HH:MM:SS' o 'MM:SS' a segundos.\"\"\"\n",
    "    try:\n",
    "        # AÃ±adido para limpiar timestamps como '00:03:05.123'\n",
    "        time_str = time_str.split('.')[0]\n",
    "        parts = list(map(int, time_str.split(':')))\n",
    "        if len(parts) == 3:  # HH:MM:SS\n",
    "            h, m, s = parts\n",
    "            return h * 3600 + m * 60 + s\n",
    "        elif len(parts) == 2:  # MM:SS\n",
    "            m, s = parts\n",
    "            return m * 60 + s\n",
    "        else:\n",
    "            raise ValueError(\"Formato de tiempo no vÃ¡lido\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error al convertir tiempo '{time_str}': {e}\", file=sys.stderr)\n",
    "        return 0\n",
    "\n",
    "# --- Â¡FUNCIÃ“N MODIFICADA! ---\n",
    "def leer_subtitulos_locales(vtt_path):\n",
    "    \"\"\"\n",
    "    Lee un archivo .vtt local y lo devuelve\n",
    "    como un texto formateado Y como un objeto webvtt.\n",
    "    \"\"\"\n",
    "    captions = None\n",
    "    transcript = \"\"\n",
    "\n",
    "    try:\n",
    "        print(f\"Leyendo archivo de subtÃ­tulos local: {vtt_path}...\")\n",
    "        if not os.path.exists(vtt_path):\n",
    "             raise FileNotFoundError(f\"No se pudo encontrar el archivo .vtt local: {vtt_path}\")\n",
    "\n",
    "        # La lÃ³gica de parseo del script original es buena, la reutilizamos\n",
    "        captions = webvtt.read(vtt_path)\n",
    "        for caption in captions:\n",
    "            # Usamos la conversiÃ³n de segundos para consistencia\n",
    "            secs = int(caption.start_in_seconds)\n",
    "            h = secs // 3600\n",
    "            m = (secs % 3600) // 60\n",
    "            s = secs % 60\n",
    "            timestamp = f\"{h:02}:{m:02}:{s:02}\"\n",
    "            transcript += f\"[{timestamp}] {caption.text.strip().replace(chr(10), ' ')}\\n\"\n",
    "\n",
    "        print(\"SubtÃ­tulos leÃ­dos y formateados exitosamente.\")\n",
    "        return transcript, captions\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extrayendo subtÃ­tulos locales: {e}\", file=sys.stderr)\n",
    "        return None, None\n",
    "\n",
    "def obtener_clips_con_gemini(api_key, transcript):\n",
    "    \"\"\"\n",
    "    EnvÃ­a la transcripciÃ³n a Gemini y le pide que identifique\n",
    "    secciones para shorts, devolviendo un JSON.\n",
    "    (FunciÃ³n sin cambios)\n",
    "    \"\"\"\n",
    "    print(\"Conectando con Gemini para analizar momentos clave...\")\n",
    "    try:\n",
    "        genai.configure(api_key=api_key)\n",
    "\n",
    "        model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        Eres un experto productor de video y creador de contenido viral\n",
    "        para YouTube Shorts.\n",
    "\n",
    "        Tu tarea es analizar la siguiente transcripciÃ³n de un video\n",
    "        (con marcas de tiempo [HH:MM:SS]) e identificar los 3 a 5\n",
    "        momentos mÃ¡s impactantes, educativos o \"virales\" que serÃ­an\n",
    "        perfectos para YouTube Shorts.\n",
    "\n",
    "        Reglas para los clips:\n",
    "        1. Cada clip debe tener una duraciÃ³n ideal de 30 a 55 segundos.\n",
    "        2. Los clips no deben superponerse.\n",
    "        3. Busca \"ganchos\" (preguntas, declaraciones impactantes),\n",
    "           resÃºmenes de puntos clave o conclusiones claras.\n",
    "        4. **REGLA CRÃTICA DE COMPLETITUD:** El timestamp de 'fin' DEBE\n",
    "           corresponder al final de una oraciÃ³n o una idea completa.\n",
    "           No cortes al orador a mitad de frase. Es PREFERIBLE que el\n",
    "           clip dure unos segundos mÃƒÂ¡s (hasta 59 segundos) para\n",
    "           asegurar que la idea se concluya, en lugar de cortarlo\n",
    "           abruptamente.\n",
    "\n",
    "        Tu respuesta DEBE ser Ãºnicamente un objeto JSON, sin ningÃºn\n",
    "        otro texto, markdown o explicaciÃƒÂ³n.\n",
    "\n",
    "        El formato JSON debe ser una lista de objetos, donde cada\n",
    "        objeto tiene tres claves:\n",
    "        - \"nombre\": Un tÃ­tulo corto y pegadizo para el clip (usa guiones bajos, sin espacios).\n",
    "        - \"inicio\": El timestamp 'HH:MM:SS' de inicio.\n",
    "        - \"fin\": El timestamp 'HH:MM:SS' de fin.\n",
    "\n",
    "        Ejemplo de respuesta:\n",
    "        [\n",
    "          {{\"nombre\": \"Error_Comun_al_Estudiar\", \"inicio\": \"00:03:05\", \"fin\": \"00:03:52\"}},\n",
    "          {{\"nombre\": \"ReseÃ±a_Libro_Saunders\", \"inicio\": \"00:08:05\", \"fin\": \"00:08:47\"}}\n",
    "        ]\n",
    "\n",
    "        AquÃ­ estÃ¡ la transcripciÃ³n:\n",
    "        ---\n",
    "        {transcript}\n",
    "        ---\n",
    "        \"\"\"\n",
    "\n",
    "        response = model.generate_content(prompt)\n",
    "\n",
    "        cleaned_response = response.text.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "\n",
    "        print(\"AnÃ¡lisis de IA completado. Parseando secciones...\")\n",
    "        secciones = json.loads(cleaned_response)\n",
    "        return secciones\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error al contactar con Gemini o parsear JSON: {e}\", file=sys.stderr)\n",
    "        if \"404\" in str(e) and \"is not found\" in str(e):\n",
    "            print(\"\\n--- Â¡PROBLEMA DE API! ---\", file=sys.stderr)\n",
    "            print(\"Error 404: El modelo no se encuentra.\", file=sys.stderr)\n",
    "            print(\"Esto casi siempre significa que tu API KEY tiene un problema.\", file=sys.stderr)\n",
    "            print(\"1. Tu clave de API fue (o serÃ¡) desactivada por seguridad.\", file=sys.stderr)\n",
    "            print(\"2. Debes habilitar la API 'Generative Language API' en tu proyecto de Google Cloud.\", file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "# --- Â¡FUNCIÃ“N MODIFICADA! ---\n",
    "def cortar_video_clips(video_local_path, secciones, captions_obj):\n",
    "    \"\"\"\n",
    "    Usa el video local, corta las secciones de la IA\n",
    "    y guarda un .txt con el subtÃ­tulo de cada una.\n",
    "    \"\"\"\n",
    "    video_original_path = \"video_original.mp4\" # Nombre temporal\n",
    "\n",
    "    try:\n",
    "        # --- Â¡BLOQUE DE DESCARGA ELIMINADO! ---\n",
    "        # Reemplazado por una copia local\n",
    "        print(f\"Usando video local: {video_local_path}\")\n",
    "        if not os.path.exists(video_local_path):\n",
    "            raise FileNotFoundError(f\"No se pudo encontrar el video en: {video_local_path}\")\n",
    "        \n",
    "        print(f\"Copiando video a la ruta de trabajo temporal: {video_original_path}...\")\n",
    "        shutil.copy(video_local_path, video_original_path)\n",
    "        print(\"Copia completada.\")\n",
    "        # --- FIN DE LA MODIFICACIÃ“N ---\n",
    "\n",
    "        output_folder = \"shorts_generados_por_ia\"\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "\n",
    "        for seccion in secciones:\n",
    "            nombre = seccion['nombre']\n",
    "            inicio_str = seccion['inicio']\n",
    "            fin_str = seccion['fin']\n",
    "\n",
    "            video = None\n",
    "            clip_original = None\n",
    "            clip_recortado = None\n",
    "\n",
    "            try:\n",
    "                # Esta parte funciona igual, ya que usa el archivo temporal\n",
    "                video = VideoFileClip(video_original_path)\n",
    "\n",
    "                inicio_seg = to_seconds(inicio_str)\n",
    "                fin_seg = to_seconds(fin_str)\n",
    "\n",
    "                if fin_seg > video.duration:\n",
    "                    print(f\"Advertencia: Tiempo final '{fin_str}' excede duraciÃ³n. Cortando al final del video.\")\n",
    "                    fin_seg = video.duration\n",
    "\n",
    "                if inicio_seg >= fin_seg:\n",
    "                    print(f\"Advertencia: Tiempo de inicio '{inicio_str}' es mayor o igual al de fin '{fin_str}'. Saltando clip.\")\n",
    "                    continue\n",
    "\n",
    "                print(f\"Creando clip IA: {nombre} ({inicio_str} a {fin_str})...\")\n",
    "\n",
    "                clip_original = video.subclip(inicio_seg, fin_seg)\n",
    "\n",
    "                (w, h) = clip_original.size\n",
    "                target_width = h * 9 / 16\n",
    "                x_center = w / 2\n",
    "                x1 = x_center - (target_width / 2)\n",
    "                x2 = x_center + (target_width / 2)\n",
    "                clip_recortado = clip_original.crop(x1=x1, y1=0, x2=x2, y2=h)\n",
    "\n",
    "                output_path = os.path.join(output_folder, f\"{nombre}.mp4\")\n",
    "                clip_recortado.write_videofile(output_path,\n",
    "                                              codec=\"libx264\",\n",
    "                                              audio_codec=\"aac\",\n",
    "                                              logger=None)\n",
    "\n",
    "                print(f\"Clip '{nombre}' creado exitosamente.\")\n",
    "\n",
    "                # --- LÃ³gica para guardar .txt (sin cambios) ---\n",
    "                texto_del_short = []\n",
    "                if captions_obj:\n",
    "                    for caption in captions_obj:\n",
    "                        if caption.start_in_seconds < fin_seg and caption.end_in_seconds > inicio_seg:\n",
    "                            clean_text = caption.text.strip().replace('\\n', ' ')\n",
    "                            texto_del_short.append(clean_text)\n",
    "\n",
    "                texto_completo = \"\\n\".join(texto_del_short)\n",
    "                txt_output_path = os.path.join(output_folder, f\"{nombre}.txt\")\n",
    "\n",
    "                try:\n",
    "                    with open(txt_output_path, 'w', encoding='utf-8') as f:\n",
    "                        f.write(texto_completo)\n",
    "                    print(f\"Texto del clip '{nombre}' guardado en .txt.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Advertencia: No se pudo guardar el .txt para '{nombre}': {e}\")\n",
    "                # --- FIN DE LA SECCIÃ“N ---\n",
    "\n",
    "            finally:\n",
    "                if clip_recortado: clip_recortado.close()\n",
    "                if clip_original: clip_original.close()\n",
    "                if video: video.close()\n",
    "        \n",
    "        # Limpiamos el video temporal copiado\n",
    "        os.remove(video_original_path)\n",
    "        print(f\"\\nÂ¡Proceso completado! Los shorts y .txt estÃ¡n en la carpeta '{output_folder}'.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ha ocurrido un error al cortar los clips: {e}\", file=sys.stderr)\n",
    "        if os.path.exists(video_original_path):\n",
    "            os.remove(video_original_path)\n",
    "\n",
    "# --- ConfiguraciÃ³n Principal (Orquestador) ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # --- Â¡EDITA ESTAS LÃNEAS! ---\n",
    "    # Debes proporcionar la ruta a TUS archivos locales\n",
    "    RUTA_VIDEO_LOCAL = \"to_edit/video.mp4\"\n",
    "    RUTA_SUBTITULOS_LOCAL = \"to_edit/subs.vtt\"\n",
    "    # -----------------------------------\n",
    "\n",
    "    API_KEY = os.getenv(\"API_KEY\")\n",
    "\n",
    "    # --- Â¡CORREGIDO! ---\n",
    "    # Comprobando la variable \"API_KEY\" (en lugar de \"GEMINI_API_KEY\")\n",
    "    if not API_KEY:\n",
    "        print(\"Error: No se encontrÃ³ la variable de entorno 'API_KEY'.\", file=sys.stderr)\n",
    "        print(\"Por favor, configÃºrala antes de ejecutar el script.\", file=sys.stderr)\n",
    "        print(\" (Recuerda crear un archivo .env o exportarla en tu terminal)\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    # --- Â¡NUEVO! ComprobaciÃ³n de archivos locales (Corregida) ---\n",
    "\n",
    "    # Simplemente comprueba si la ruta NO existe.\n",
    "    if not os.path.exists(RUTA_VIDEO_LOCAL):\n",
    "        print(f\"Error: El archivo de video NO se encuentra en la ruta especificada:\", file=sys.stderr)\n",
    "        print(f\"{RUTA_VIDEO_LOCAL}\", file=sys.stderr)\n",
    "        print(\"Por favor, verifica que la variable RUTA_VIDEO_LOCAL sea correcta.\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    if not os.path.exists(RUTA_SUBTITULOS_LOCAL):\n",
    "        print(f\"Error: El archivo de subtÃ­tulos NO se encuentra en la ruta especificada:\", file=sys.stderr)\n",
    "        print(f\"{RUTA_SUBTITULOS_LOCAL}\", file=sys.stderr)\n",
    "        print(\"Por favor, verifica que la variable RUTA_SUBTITULOS_LOCAL sea correcta.\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "        \n",
    "    # Si el script llega aquÃ­, es porque los encontrÃ³.\n",
    "    print(\"Â¡Ã‰xito! Archivos de video y subtÃ­tulos encontrados.\")\n",
    "    # ---------------------------------\n",
    "\n",
    "    try:\n",
    "        # --- Â¡MODIFICADO! ---\n",
    "        transcripcion, subtitulos_obj = leer_subtitulos_locales(RUTA_SUBTITULOS_LOCAL)\n",
    "\n",
    "        if not transcripcion or not subtitulos_obj:\n",
    "            raise Exception(\"No se pudo obtener la transcripciÃ³n o los subtÃ­tulos.\")\n",
    "\n",
    "        secciones_ai = obtener_clips_con_gemini(API_KEY, transcripcion)\n",
    "        if not secciones_ai:\n",
    "            raise Exception(\"Gemini no devolviÃ³ secciones vÃ¡lidas.\")\n",
    "\n",
    "        print(\"\\n--- Secciones identificadas por Gemini ---\")\n",
    "        print(json.dumps(secciones_ai, indent=2, ensure_ascii=False))\n",
    "        print(\"------------------------------------------\\n\")\n",
    "\n",
    "        # --- Â¡MODIFICADO! ---\n",
    "        cortar_video_clips(RUTA_VIDEO_LOCAL, secciones_ai, subtitulos_obj)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"El proceso fallÃ³: {e}\", file=sys.stderr)\n",
    "        sys.exit(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
